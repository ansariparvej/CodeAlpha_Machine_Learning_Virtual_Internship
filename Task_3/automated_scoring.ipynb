{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrmsmArX8Ttz"
   },
   "source": [
    "# MACHINE LEARNING INTERN @ CODE ALPHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59QFIpy88Wvx"
   },
   "source": [
    "### AUTHOR : PARVEJ ALAM M. ANSARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGmCmxCQ8W45"
   },
   "source": [
    "## TASK 3: AUTOMATED ESSAY SCORING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6QD_LKK8bwB"
   },
   "source": [
    "### The dataset is available at Kaggle:\n",
    "### https://www.kaggle.com/competitions/mum-fit1043-s1-2021/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXxnYuBStmK0"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eQkNE5jtmK1"
   },
   "source": [
    "The purpose of this report is to read and preprocess data derived from a set of essays, then conduct predictive analysis on this data using machine learning, and finally to evaluate the accuracy of the predictions. The dataset consists of numeric information on a set of student-written essays and with this information the goal is to create an appropriate machine learning model to perform automated essay scoring.\n",
    "\n",
    "The report has the following outline:\n",
    "1. Introduction\n",
    "2. Downloading and Importing Libraries\n",
    "3. Reading and Describing the Data\n",
    "4. Supervised Learning\n",
    "5. Feature Selection\n",
    "6. Splitting Data into Train/Test Set\n",
    "7. Classification\n",
    "8. Normalization/Standardization\n",
    "8. SVM\n",
    "10. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fSzu08ctmK2"
   },
   "source": [
    "# Downloading and Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-tdhZdWtmK3"
   },
   "source": [
    "### &emsp;Downloading Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzCiKtAHtmK3"
   },
   "source": [
    "The first step is to download the libraries that are used in this report.\n",
    "\n",
    "Here, there is only one library to download and it is *imbalanced-learn* which is an open-source library that provides tools to aid in classification when there are imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9v1gePCXtmK6"
   },
   "source": [
    "### &emsp;Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IohwX_LHtmK8"
   },
   "source": [
    "After downloading the required libraries, we need to import the necessary libraries and modules:\n",
    "1. **pandas**, which is an open source data analysis tool for python. It allows the usage of convenient data structures such as ***DataFrame*** along with a collection of functions that will greatly aid in reading files and manipulating DataFrames. We can also use the *as* keyword to specify a simpler, and shorter name - *pd* to refer to the library from this point onwards.\n",
    "2. **numpy**, which is an open source python library that is very useful when working with arrays and matrices. It also provides a large collection of mathematical functions to operate on these arrays. Here we use the *as* keyword to specify a simpler, and shorter name - *np* to refer to the library from this point onwards.\n",
    "3. **sklearn**, also known as scikit-learn is an open-source machine learning library for python. It provides easy-to-use tools for predictive data analysis and features a vast range of classification, regression, and clustering algorithms. Here we are importing the various modules in the library instead of just importing the library for ease of use.\n",
    "4. **imblearn**, also known as imbalanced-learn, is an open-source library that can improve accuracy of classification algorithms when there are imbalanced classes\n",
    "5. **collections** is a built-in python module which implements specialized container datatypes but here we are only using the Counter class from this module that is used for counting hashable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FS9NTLOztmK9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8kHvV5dtmK-"
   },
   "source": [
    "# Reading and Describing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7F7XjVitmK_"
   },
   "source": [
    "### &emsp;Reading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZGt1qxXtmK_"
   },
   "source": [
    "Read the data from the *'essay_features.csv'* file with the *.read_csv* function from pandas and assign the resulting DataFrame to the *essay_data* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y_udvI2RtmK_"
   },
   "outputs": [],
   "source": [
    "essay_data = pd.read_csv('/content/sample_data/essay_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moqGmD6qtmLA"
   },
   "source": [
    "#### &emsp;&emsp;Ensuring the data was read correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRdQRn1BtmLA"
   },
   "source": [
    "To ensure that the file has been read properly, we can first check whether the resulting DataFrame has the same number of rows and columns as the original csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22nAuJmdtmLB",
    "outputId": "1167fa2b-434f-460d-ef79-e2575060c540"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1CkmvRFtmLC"
   },
   "source": [
    "The output shows that there are 1332 rows and 19 columns. Comparing this with the original csv file, which also has 1332 rows (excluding the first row which is used as a header and is thus not counted as a row in the DataFrame) and 19 columns, we can see that the resulting DataFrame has the same number of rows and columns as the original file.\n",
    "\n",
    "Next we can display the first and last 5 rows of the *essay_data* DataFrame to check whether the contents of the cells have been read properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "kc_Ws4u4tmLC",
    "outputId": "c5b8f44a-e171-4443-a47e-ba917404a947"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"essay_data\",\n  \"rows\": 1332,\n  \"fields\": [\n    {\n      \"column\": \"essayid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 526,\n        \"min\": 0,\n        \"max\": 1799,\n        \"num_unique_values\": 1332,\n        \"samples\": [\n          163,\n          1194,\n          196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 865,\n        \"min\": 169,\n        \"max\": 6142,\n        \"num_unique_values\": 1064,\n        \"samples\": [\n          1985,\n          1781,\n          6142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 171,\n        \"min\": 36,\n        \"max\": 1170,\n        \"num_unique_values\": 580,\n        \"samples\": [\n          58,\n          488,\n          415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 72,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          14,\n          10,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"apostrophes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2,\n        \"max\": 51,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          27,\n          3,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"punctuations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          0,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23107146022809866,\n        \"min\": 2.231321839,\n        \"max\": 5.6814285710000005,\n        \"num_unique_values\": 1302,\n        \"samples\": [\n          5.195826645,\n          4.971509972,\n          5.054176072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 642,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          20,\n          52,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          17,\n          10,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.160020046143805,\n        \"min\": 1.08411215,\n        \"max\": 303.0,\n        \"num_unique_values\": 1068,\n        \"samples\": [\n          20.1,\n          34.58823529,\n          33.52631579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170.98511051781273,\n        \"min\": 35.64705882,\n        \"max\": 1158.984563,\n        \"num_unique_values\": 1208,\n        \"samples\": [\n          450.9911308,\n          639.6500778,\n          168.98809519999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007308354612039425,\n        \"min\": 0.924771388,\n        \"max\": 1.0,\n        \"num_unique_values\": 1263,\n        \"samples\": [\n          0.982283775,\n          0.988599957,\n          0.990954591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 82,\n        \"min\": 14,\n        \"max\": 669,\n        \"num_unique_values\": 341,\n        \"samples\": [\n          344,\n          25,\n          264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.052466048998499465,\n        \"min\": 0.288888889,\n        \"max\": 0.961206897,\n        \"num_unique_values\": 1225,\n        \"samples\": [\n          0.487179487,\n          0.436399217,\n          0.4441558439999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43,\n        \"min\": 11,\n        \"max\": 355,\n        \"num_unique_values\": 216,\n        \"samples\": [\n          186,\n          28,\n          156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038870417437443114,\n        \"min\": 0.027298851,\n        \"max\": 0.465517241,\n        \"num_unique_values\": 1223,\n        \"samples\": [\n          0.256684492,\n          0.225641026,\n          0.241167435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unstemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159,\n        \"min\": 48,\n        \"max\": 750,\n        \"num_unique_values\": 509,\n        \"samples\": [\n          582,\n          169,\n          597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155,\n        \"min\": 50,\n        \"max\": 750,\n        \"num_unique_values\": 510,\n        \"samples\": [\n          244,\n          474,\n          666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "essay_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f74e3267-6151-4907-831d-46b39a0a70e1\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f74e3267-6151-4907-831d-46b39a0a70e1')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f74e3267-6151-4907-831d-46b39a0a70e1 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f74e3267-6151-4907-831d-46b39a0a70e1');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-336b003c-d0d1-41a3-b522-260b74c4be19\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-336b003c-d0d1-41a3-b522-260b74c4be19')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-336b003c-d0d1-41a3-b522-260b74c4be19 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   essayid  chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0     1457   2153    426      14            6             0         5.053991   \n",
       "1      503   1480    292       9            7             0         5.068493   \n",
       "2      253   3964    849      19           26             1         4.669022   \n",
       "3      107    988    210       8            7             0         4.704762   \n",
       "4     1450   3139    600      13            8             0         5.231667   \n",
       "\n",
       "   sentences  questions  avg_word_sentence         POS  POS/total_words  \\\n",
       "0         16          0          26.625000  423.995272         0.995294   \n",
       "1         11          0          26.545455  290.993103         0.996552   \n",
       "2         49          2          17.326531  843.990544         0.994100   \n",
       "3         12          0          17.500000  207.653784         0.988828   \n",
       "4         24          1          25.000000  594.652150         0.991087   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0           207                  0.485915            105   \n",
       "1           148                  0.506849             77   \n",
       "2           285                  0.335689            130   \n",
       "3           112                  0.533333             62   \n",
       "4           255                  0.425000            165   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                   0.246479        424      412      4  \n",
       "1                   0.263699        356      345      4  \n",
       "2                   0.153121        750      750      4  \n",
       "3                   0.295238        217      209      3  \n",
       "4                   0.275000        702      677      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "HHcIfVkatmLC",
    "outputId": "081b4250-cace-4294-d395-edd72f6f8775"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"essay_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"essayid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 379,\n        \"min\": 344,\n        \"max\": 1345,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1015,\n          1077,\n          1345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 674,\n        \"min\": 1182,\n        \"max\": 2806,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1182,\n          2806,\n          1814\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 124,\n        \"min\": 241,\n        \"max\": 542,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          241,\n          542,\n          363\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 0,\n        \"max\": 24,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          24,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"apostrophes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 6,\n        \"max\": 14,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          6,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"punctuations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11746303735608254,\n        \"min\": 4.904564315,\n        \"max\": 5.177121771,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.904564315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 13,\n        \"max\": 22,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.759034528436984,\n        \"min\": 15.0625,\n        \"max\": 27.92307692,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15.0625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 124.01049766063379,\n        \"min\": 238.6554622,\n        \"max\": 538.9888889,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          238.6554622\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031515258552180744,\n        \"min\": 0.990271627,\n        \"max\": 0.998153278,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.990271627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 94,\n        \"max\": 284,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.054259743899299905,\n        \"min\": 0.390041494,\n        \"max\": 0.52398524,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.390041494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 67,\n        \"max\": 155,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021025618974217515,\n        \"min\": 0.241970021,\n        \"max\": 0.29476584,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2780082989999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unstemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 129,\n        \"min\": 293,\n        \"max\": 596,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 283,\n        \"max\": 575,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0f8b92cc-312d-43fb-bc3b-4d04018cb302\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.227273</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>0.991407</td>\n",
       "      <td>200</td>\n",
       "      <td>0.428266</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>94</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>27.923077</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>170</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22.076923</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>144</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24.636364</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>284</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f8b92cc-312d-43fb-bc3b-4d04018cb302')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0f8b92cc-312d-43fb-bc3b-4d04018cb302 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0f8b92cc-312d-43fb-bc3b-4d04018cb302');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a8b502df-675a-4062-8567-ba234b5f1f95\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8b502df-675a-4062-8567-ba234b5f1f95')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a8b502df-675a-4062-8567-ba234b5f1f95 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "1327     1151   2404    467      16           10             0   \n",
       "1328     1015   1182    241       0           14             0   \n",
       "1329     1345   1814    363       5           11             0   \n",
       "1330      344   1427    287       5            8             0   \n",
       "1331     1077   2806    542      24            6             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "1327         5.147752         22          0          21.227273  462.987069   \n",
       "1328         4.904564         16          0          15.062500  238.655462   \n",
       "1329         4.997245         13          3          27.923077  362.329640   \n",
       "1330         4.972125         13          1          22.076923  284.657277   \n",
       "1331         5.177122         22          3          24.636364  538.988889   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "1327         0.991407           200                  0.428266            113   \n",
       "1328         0.990272            94                  0.390041             67   \n",
       "1329         0.998153           170                  0.468320            107   \n",
       "1330         0.991837           144                  0.501742             83   \n",
       "1331         0.994444           284                  0.523985            155   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "1327                   0.241970        529      519      4  \n",
       "1328                   0.278008        293      283      3  \n",
       "1329                   0.294766        427      415      3  \n",
       "1330                   0.289199        323      312      3  \n",
       "1331                   0.285978        596      575      4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKwqosfLtmLD"
   },
   "source": [
    "With this we can be certain that the data has been read properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OT-lyXeqtmLE"
   },
   "source": [
    "### &emsp;Describing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhAA40TNtmLE"
   },
   "source": [
    "All of the column values are numeric, however, note that the last column (*score*) is numeric, discrete, *and* categorical. This is because it can only take one of 6 discrete values (1, 2, 3, 4, 5, or 6).\n",
    "\n",
    "***Central tendency:***\n",
    "- **essayid**\n",
    "    - *Note that this column contains the unique ids of the essays and has no bearing on the content of the essay itself, thus these statistical descriptions might not be particularly meaningful or useful*\n",
    "    - The average essay id is 905\n",
    "    - The median essay id is 915\n",
    "- **chars**\n",
    "    - The average number of characters in an essay is 2102\n",
    "    - The median number of characters in an essay is 2030\n",
    "- **words**\n",
    "    - The average number of words in an essay is 424\n",
    "    - The median number of words in an essay is 411\n",
    "- **commas**\n",
    "    - The average number of commas in an essay is 15\n",
    "    - The median number of commas in an essay is 13\n",
    "- **apostrophes**\n",
    "    - The average number of apostrophes in an essay is 8.1\n",
    "    - The median number of apostrophes in an essay is 6.0\n",
    "- **punctuations**\n",
    "    - *Note that punctuations here excludes commas, apostrophes, period, question marks*\n",
    "    - The average number of punctuations in an essay is 0.5\n",
    "    - The median number of punctuations in an essay is 0.0\n",
    "- **avg_word_length**\n",
    "    - The average number of characters in a word in an essay is 4.9\n",
    "    - The median number of characters in a word in an essay is also 4.9\n",
    "- **sentences**\n",
    "    - The average number of sentences in an essay is 20\n",
    "    - The median number of sentences in an essay is 18\n",
    "- **questions**\n",
    "    - The average number of questions in an essay is 1.2\n",
    "    - The median number of questions in an essay is 1.0\n",
    "- **avg_word_sentence**\n",
    "    - The average number of words per sentence in an essay is 24\n",
    "    - The median number of words per sentence in an essay is 22\n",
    "- **POS**\n",
    "    - *Total number of Part-of-Speech discovered in the essay. This means the number of words that have similar grammatical properties*\n",
    "    - The average number of Part-of-Speech discovered in an essay is 421\n",
    "    - The median number of Part-of-Speech discovered in an essay is 407\n",
    "- **POS/total_words**\n",
    "    - The average ratio of Part-of-Speech discovered to the total number of words in an essay is 1.0\n",
    "    - The median ratio of Part-of-Speech discovered to the total number of words in an essay is also 1.0\n",
    "- **prompt_words**\n",
    "    - The average number of words related to the prompt in an essay is 199\n",
    "    - The median number of words related to the prompt in an essay is 193\n",
    "- **prompt_words/total_words**\n",
    "    - The average ratio of the number of words related to the prompt to the total number of words in an essay is 0.5\n",
    "    - The median ratio of the number of words related to the prompt to the total number of words in an essay is also 0.5\n",
    "- **synonym_words**\n",
    "    - The average number of synonymous words in an essay is 110\n",
    "    - The median number of synonymous words in an essay is 108\n",
    "- **synonym_words/total_words**\n",
    "    - The average ratio of the number of synonymous words to the total number of words in an essay is 0.3\n",
    "    - The median ratio of the number of synonymous words to the total number of words in an essay is also 0.3\n",
    "- **unstemmed**\n",
    "    - *Unstemmed words refers to words that cannot be further reduced to their base forms*\n",
    "    - The average number of unstemmed words in an essay is 469\n",
    "    - The median number of unstemmed words in an essay is 463\n",
    "- **stemmed**\n",
    "    - *Stemmed words refers to words that **can** be further reduced to their base forms*\n",
    "    - The average number of stemmed words in an essay is 456\n",
    "    - The median number of stemmed words in an essay is 448\n",
    "- **score**\n",
    "    - The average rating of an essay is 3.4\n",
    "    - The median rating of an essay is 3.0\n",
    "    \n",
    "***Variability***:\n",
    "\n",
    "*Range can be calculated by subtracting the smallest value in a column from the largest value in a column (max - min)*\n",
    "- **essayid**\n",
    "    - There is a large range of 1799 between the maximum and minimum essay ids\n",
    "    - The variance in the essay id between essays is 277400\n",
    "- **chars**\n",
    "    - There is a large range of 5973 between the essay with the most characters and the essay with the least number of characters\n",
    "    - The variance in the number of characters between essay is 749893\n",
    "- **words**\n",
    "    - There is a large range of 1134 between the essay with the most words and the essay with the least number of words\n",
    "    - The variance in the number of words between essays is 29541\n",
    "- **commas**\n",
    "    - There is a very large range of 72 between the essay with the most commas and the essay with the least number of commas\n",
    "    - The variance in the number of commas between essays is 119\n",
    "- **apostrophes**\n",
    "    - There is a large range of 49 between the essay with the most apostrophes and the essay with the least number of apostrophes\n",
    "    - The variance in the number of apostrophes between essays is 37.5\n",
    "- **punctuations**\n",
    "    - There is a very large range of 26 (seeing as the mean is only 0.5) between the essay with the most punctuations and the essay with the least number of punctuations\n",
    "    - The variance in the number of punctuations between essays is 1.6\n",
    "- **avg_word_length**\n",
    "    - There is a relatively small range of 3.5 between the essay with the highest average word length and the essay with the lowest average word length\n",
    "    - The variance in the average word length between essays is 0.053\n",
    "- **sentences**\n",
    "    - There is a very large range of 642 between the essay with the most number of sentences and the essay with the least number of sentences\n",
    "    - The variance in the number of sentences between essays is 369\n",
    "- **questions**\n",
    "    - There is a large range of 17 (seeing as the mean is 1.2) between the essay with the most number of questions and the essay with the least number of questions\n",
    "    - The variance in the number of questions between essays is 3.4\n",
    "- **avg_word_sentence**\n",
    "    - There is a very large range of 302 between the essay with the highest average number of words per sentence and the essay with the lowest average number of words per sentence\n",
    "    - The variance in the number of average words per sentence between essays is 124.5\n",
    "- **POS**\n",
    "    - There is a very large range of 1123 between the essay with the most number of POS discovered and the essay with the least number of POS discovered\n",
    "    - The variance in the number of Part-Of-Speech between essays is 29236\n",
    "- **POS/total_words**\n",
    "    - There is a very small range of 0.08 between the essay with the highest number of Part-Of-Speech discovered per total words and the essay with the lowest number of Part-Of-Speech discovered per total words\n",
    "    - The variance in the number of Part-Of-Speech per total number of words between essays is 5.3e-5\n",
    "- **prompt_words**\n",
    "    - There is a large range of 655 between the essay with the most number of prompt words and the essay with the least number of prompt words\n",
    "    - The variance in the number of words related to the prompt between essays is 6844\n",
    "- **prompt_words/total_words**\n",
    "    - There is a range of 0.67 between the essay with the highest proportion of prompt words to total words and the essay with the lowest proportion of prompt words to total words\n",
    "    - The variance in the ratio of words related to the prompt to the total number of words between essays is 2.8e-3\n",
    "- **synonym_words**\n",
    "    - There is a range of 344 between the essay with the highest number of synonymous words and the essay with the lowest number of synonymous words\n",
    "    - The variance in the number of synonymous words between essays is 1933\n",
    "- **synonym_words/total_words**\n",
    "    - There is a relatively large range of 0.4 between the essay with the highest proportion of synonymous words to total words and the essay with the lowest proportion of synonymous words to total words\n",
    "    - The variance in the ratio of synonymous words to the total number of words between essays is 1.5e-3\n",
    "- **unstemmed**\n",
    "    - There is a large range of 702 between the essay with the highest number of unstemmed words and the essay with the lowest number of unstemmed words\n",
    "    - The variance in the number of unstemmed words (words that were not reduced further to their base form) between essays is 25423\n",
    "- **stemmed**\n",
    "    - There is a large range of 700 between the maximum and minimum number of stemmed words (words that have been reduced further to their base form) in an essay\n",
    "    - The variance in the number of stemmed words (words that have been reduced further to their base form) between essays is 24258\n",
    "- **score**\n",
    "    - There is a range of 5 between the maximum and minimum score of an essay, which makes sense since the possible scores are 1, 2, 3, 4, 5, or 6\n",
    "    - The variance in the score between essays is 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "1feZidFOtmLG",
    "outputId": "ed8f5357-3dcf-49d0-afee-b5e18ce484f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"essay_data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"essayid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 582.256233069179,\n        \"min\": 0.0,\n        \"max\": 1799.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          905.2702702702703,\n          914.5,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1803.7994526229993,\n        \"min\": 169.0,\n        \"max\": 6142.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2101.7454954954956,\n          2029.5,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 462.34666767688407,\n        \"min\": 36.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          424.4857357357357,\n          411.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 464.46169923298834,\n        \"min\": 0.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.667417417417417,\n          13.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"apostrophes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 466.7457964477534,\n        \"min\": 2.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8.14114114114114,\n          6.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"punctuations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 469.6178325187711,\n        \"min\": 0.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4797297297297297,\n          26.0,\n          1.2716798236117335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 469.52684762852437,\n        \"min\": 0.23107146022809866,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.93976216095045,\n          4.946059456,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 486.0458699301406,\n        \"min\": 0.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19.704204204204203,\n          18.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 469.8017710805428,\n        \"min\": 0.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1332.0,\n          1.222972972972973,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 461.44598810933974,\n        \"min\": 1.08411215,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          23.884686874754504,\n          22.03033088,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 461.083026441677,\n        \"min\": 35.64705882,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          420.59654169567574,\n          406.9828691,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 470.6354589522161,\n        \"min\": 0.007308354612039425,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.9899351385195196,\n          0.9915724335,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 439.2119324880282,\n        \"min\": 14.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          198.91366366366367,\n          193.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 470.7729091949571,\n        \"min\": 0.052466048998499465,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.46916386821621614,\n          0.465851523,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 440.6789303914854,\n        \"min\": 11.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          110.16966966966967,\n          107.5,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 470.85307748378415,\n        \"min\": 0.027298851,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.26384560256006,\n          0.26287187050000005,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unstemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 396.3904806760353,\n        \"min\": 48.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          468.987987987988,\n          463.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 397.33201912693903,\n        \"min\": 50.0,\n        \"max\": 1332.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          455.5075075075075,\n          448.0,\n          1332.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 469.8651894630469,\n        \"min\": 0.7742746714549265,\n        \"max\": 1332.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1332.0,\n          3.4271771771771773,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-994913dd-cd82-45f8-bb06-bf7cf064103a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.00000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>1332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>905.27027</td>\n",
       "      <td>2101.745495</td>\n",
       "      <td>424.485736</td>\n",
       "      <td>14.667417</td>\n",
       "      <td>8.141141</td>\n",
       "      <td>0.47973</td>\n",
       "      <td>4.939762</td>\n",
       "      <td>19.704204</td>\n",
       "      <td>1.222973</td>\n",
       "      <td>23.884687</td>\n",
       "      <td>420.596542</td>\n",
       "      <td>0.989935</td>\n",
       "      <td>198.913664</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>110.16967</td>\n",
       "      <td>0.263846</td>\n",
       "      <td>468.987988</td>\n",
       "      <td>455.507508</td>\n",
       "      <td>3.427177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>526.68760</td>\n",
       "      <td>865.963750</td>\n",
       "      <td>171.873730</td>\n",
       "      <td>10.920781</td>\n",
       "      <td>6.124520</td>\n",
       "      <td>1.27168</td>\n",
       "      <td>0.231071</td>\n",
       "      <td>19.202731</td>\n",
       "      <td>1.847446</td>\n",
       "      <td>11.160020</td>\n",
       "      <td>170.985111</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>82.729266</td>\n",
       "      <td>0.052466</td>\n",
       "      <td>43.96192</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>159.447449</td>\n",
       "      <td>155.751220</td>\n",
       "      <td>0.774275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.231322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.084112</td>\n",
       "      <td>35.647059</td>\n",
       "      <td>0.924771</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.027299</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>442.75000</td>\n",
       "      <td>1527.250000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.791679</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>305.406284</td>\n",
       "      <td>0.987758</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.435709</td>\n",
       "      <td>81.00000</td>\n",
       "      <td>0.238423</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>350.750000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>914.50000</td>\n",
       "      <td>2029.500000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.946059</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.030331</td>\n",
       "      <td>406.982869</td>\n",
       "      <td>0.991572</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>0.465852</td>\n",
       "      <td>107.50000</td>\n",
       "      <td>0.262872</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1369.75000</td>\n",
       "      <td>2613.500000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.092938</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.048234</td>\n",
       "      <td>520.739458</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>134.00000</td>\n",
       "      <td>0.288277</td>\n",
       "      <td>581.000000</td>\n",
       "      <td>561.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1799.00000</td>\n",
       "      <td>6142.000000</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>5.681429</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1158.984563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>355.00000</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-994913dd-cd82-45f8-bb06-bf7cf064103a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-994913dd-cd82-45f8-bb06-bf7cf064103a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-994913dd-cd82-45f8-bb06-bf7cf064103a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ca474540-38f0-4ea0-9f15-6215a292247a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca474540-38f0-4ea0-9f15-6215a292247a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ca474540-38f0-4ea0-9f15-6215a292247a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          essayid        chars        words       commas  apostrophes  \\\n",
       "count  1332.00000  1332.000000  1332.000000  1332.000000  1332.000000   \n",
       "mean    905.27027  2101.745495   424.485736    14.667417     8.141141   \n",
       "std     526.68760   865.963750   171.873730    10.920781     6.124520   \n",
       "min       0.00000   169.000000    36.000000     0.000000     2.000000   \n",
       "25%     442.75000  1527.250000   310.000000     7.000000     4.000000   \n",
       "50%     914.50000  2029.500000   411.000000    13.000000     6.000000   \n",
       "75%    1369.75000  2613.500000   525.000000    21.000000    11.000000   \n",
       "max    1799.00000  6142.000000  1170.000000    72.000000    51.000000   \n",
       "\n",
       "       punctuations  avg_word_length    sentences    questions  \\\n",
       "count    1332.00000      1332.000000  1332.000000  1332.000000   \n",
       "mean        0.47973         4.939762    19.704204     1.222973   \n",
       "std         1.27168         0.231071    19.202731     1.847446   \n",
       "min         0.00000         2.231322     0.000000     0.000000   \n",
       "25%         0.00000         4.791679    13.000000     0.000000   \n",
       "50%         0.00000         4.946059    18.000000     1.000000   \n",
       "75%         0.00000         5.092938    24.000000     2.000000   \n",
       "max        26.00000         5.681429   642.000000    17.000000   \n",
       "\n",
       "       avg_word_sentence          POS  POS/total_words  prompt_words  \\\n",
       "count        1332.000000  1332.000000      1332.000000   1332.000000   \n",
       "mean           23.884687   420.596542         0.989935    198.913664   \n",
       "std            11.160020   170.985111         0.007308     82.729266   \n",
       "min             1.084112    35.647059         0.924771     14.000000   \n",
       "25%            19.142857   305.406284         0.987758    144.000000   \n",
       "50%            22.030331   406.982869         0.991572    193.000000   \n",
       "75%            26.048234   520.739458         0.994425    246.000000   \n",
       "max           303.000000  1158.984563         1.000000    669.000000   \n",
       "\n",
       "       prompt_words/total_words  synonym_words  synonym_words/total_words  \\\n",
       "count               1332.000000     1332.00000                1332.000000   \n",
       "mean                   0.469164      110.16967                   0.263846   \n",
       "std                    0.052466       43.96192                   0.038870   \n",
       "min                    0.288889       11.00000                   0.027299   \n",
       "25%                    0.435709       81.00000                   0.238423   \n",
       "50%                    0.465852      107.50000                   0.262872   \n",
       "75%                    0.500000      134.00000                   0.288277   \n",
       "max                    0.961207      355.00000                   0.465517   \n",
       "\n",
       "         unstemmed      stemmed        score  \n",
       "count  1332.000000  1332.000000  1332.000000  \n",
       "mean    468.987988   455.507508     3.427177  \n",
       "std     159.447449   155.751220     0.774275  \n",
       "min      48.000000    50.000000     1.000000  \n",
       "25%     361.000000   350.750000     3.000000  \n",
       "50%     463.000000   448.000000     3.000000  \n",
       "75%     581.000000   561.250000     4.000000  \n",
       "max     750.000000   750.000000     6.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate descriptive statistics for the essay_data DataFrame\n",
    "essay_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "W565Sjc5tmLG",
    "outputId": "69f33909-ec89-4eb3-950b-19dbe7e8720d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>essayid</th>\n",
       "      <td>277399.827726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chars</th>\n",
       "      <td>749893.216171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>29540.579060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commas</th>\n",
       "      <td>119.263460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apostrophes</th>\n",
       "      <td>37.509741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punctuations</th>\n",
       "      <td>1.617170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word_length</th>\n",
       "      <td>0.053394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>368.744896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions</th>\n",
       "      <td>3.413056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <td>124.546047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>29235.908019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS/total_words</th>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_words</th>\n",
       "      <td>6844.131534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <td>0.002753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synonym_words</th>\n",
       "      <td>1932.650379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <td>0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unstemmed</th>\n",
       "      <td>25423.488962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stemmed</th>\n",
       "      <td>24258.442468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.599501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> float64</label>"
      ],
      "text/plain": [
       "essayid                      277399.827726\n",
       "chars                        749893.216171\n",
       "words                         29540.579060\n",
       "commas                          119.263460\n",
       "apostrophes                      37.509741\n",
       "punctuations                      1.617170\n",
       "avg_word_length                   0.053394\n",
       "sentences                       368.744896\n",
       "questions                         3.413056\n",
       "avg_word_sentence               124.546047\n",
       "POS                           29235.908019\n",
       "POS/total_words                   0.000053\n",
       "prompt_words                   6844.131534\n",
       "prompt_words/total_words          0.002753\n",
       "synonym_words                  1932.650379\n",
       "synonym_words/total_words         0.001511\n",
       "unstemmed                     25423.488962\n",
       "stemmed                       24258.442468\n",
       "score                             0.599501\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the variance for each column\n",
    "essay_data.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsM0maaatmLG"
   },
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJ1mVuJAtmLH"
   },
   "source": [
    "### &emsp;Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vlkn-caitmLH"
   },
   "source": [
    "**Supervised Machine Learning** is a subcategory of machine learning which involves training an algorithm on data that is well labeled, i.e. labeled training data. The goal is to obtain an approximation of the function that maps the input to the output so that when it is provided with new input data, it is able to predict the output for that data (IBM Cloud Education, 2020; Brownlee, 2020).\n",
    "\n",
    "In the context of machine learning, **labeled data** refers to data that has one or more meaningful labels or informative tags that can be used by supervised machine learning models to learn the combination of features that might map the input to that label, and thus be able to predict labels for unlabelled data. For example, given a picture the label might indicate whether the picture contains a cat or not (Amazon Web Services, n.d.).\n",
    "\n",
    "In machine learning, the original dataset is usually divided into the **training set** and the **test set**, with the training set typically many times larger than the test set (usually an 80/20 split), where the training set is a subset of the dataset that is used to train a model, i.e. it is a set of examples used to fit the parameters/weights of a model, and the test set is a subset of the dataset that is not used during training and is instead used to test the performance of the trained model (Google Developers, 2020). Splitting the dataset in this way is required to avoid overfitting where the model performs very well with the provided data but performs very poorly when given new data, in this sense the test set serves as a proxy for new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGbOucJptmLH"
   },
   "source": [
    "### &emsp;Separating Features and Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul1a8u92tmLI"
   },
   "source": [
    "By looking at the dataset, we can surmise that the label, i.e. what we want the model to predict, are the **scores** which represents the grade of the essay, therefore we can obtain the data labels by extracting the values from the *score* column.\n",
    "\n",
    "Here we extract the values from the last column (*score*), and assign them to the variable *label* to be used later on during preprocessing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "n12XIdSLtmLI"
   },
   "outputs": [],
   "source": [
    "# extract values from every row, last column\n",
    "label = essay_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMyYNl8_tmLJ"
   },
   "source": [
    "Here we extract the values from the first column (*essayid*) to the second last column (*stemmed*) and assign these values to the variable *features* to be used during preprocessing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Nipbwe3otmLJ"
   },
   "outputs": [],
   "source": [
    "# extract values from every row, from first to second last column (i.e. columns index 0 to 17)\n",
    "features = essay_data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ81NH4OtmLJ"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6JOCq2vtmLK"
   },
   "source": [
    "Before splitting the data into the training set and the test set, we can perform feature selection to identify and select the features that will contribute most to the model's prediction. This is done to increase the model's accuracy, decrease training time, and reduce overfitting.\n",
    "\n",
    "To do this we can make use of the *f_classif()* function from the *sklearn.feature_selection* module that computes the ANOVA F-value for the provided sample and allows for feature selection when we are working with a classification problem, more specifically, when we have numerical input data (features) and a categorical target variable (label) as we do in this case.\n",
    "\n",
    "Here we can print out the F-value for each of the (feature) columns to determine which columns to keep, the higher the score the more relevant the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tvyMLqhtmLK",
    "outputId": "6c15369c-7a37-4d21-fa11-f7ac677667d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----List of features from highest to lowest F-value----\n",
      "\n",
      "unstemmed = 255.8948587663438\n",
      "stemmed = 254.33217075322452\n",
      "chars = 236.13263126536944\n",
      "POS = 209.80140389791052\n",
      "words = 208.92684234127228\n",
      "prompt_words = 186.39330700069752\n",
      "synonym_words = 135.72391926093715\n",
      "commas = 106.40189465413823\n",
      "POS/total_words = 33.979754886876925\n",
      "apostrophes = 33.93409241646121\n",
      "questions = 32.777162227254095\n",
      "avg_word_length = 32.4444185987326\n",
      "synonym_words/total_words = 28.505876406086006\n",
      "sentences = 15.93339650670346\n",
      "punctuations = 7.439281205003285\n",
      "avg_word_sentence = 5.065326414935797\n",
      "prompt_words/total_words = 1.892359146703505\n",
      "essayid = 1.1098589592655128\n"
     ]
    }
   ],
   "source": [
    "# the f_classif() function takes in the features and label data and returns the F-values for each feature\n",
    "F_vals, _ = f_classif(features, label)\n",
    "\n",
    "# gets the list of (feature) column names\n",
    "cols = essay_data.columns[:-1]\n",
    "# sort based on the F-values in descending order\n",
    "ind = np.lexsort((cols,F_vals))[::-1]\n",
    "\n",
    "print(\"----List of features from highest to lowest F-value----\\n\")\n",
    "# for each feature, display the column (feature) name along with its F-value\n",
    "for index in ind:\n",
    "    print(\"{} = {}\".format(cols[index], F_vals[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5_z9_PDtmLL"
   },
   "source": [
    "Now we can select the features which are relevant in predicting the essay's grade by defining a threshold of, say, 100 to extract the features that are most important. From the list above we can see that there are 8 features with an F-value above 100: *unstemmed, stemmed, chars, POS, words, prompt_words, synonym_words, commas*.\n",
    "\n",
    "We can now extract these 8 features and from this point onwards we will only be working and training with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y8qY2b-CtmLL"
   },
   "outputs": [],
   "source": [
    "# specify the column headers of the features we want to keep\n",
    "selected_cols = ['unstemmed', 'stemmed', 'chars', 'POS', 'words', 'prompt_words', 'synonym_words', 'commas']\n",
    "# extract the values only from the selected columns\n",
    "selected_features = essay_data[selected_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43-ndKIVtmLM"
   },
   "source": [
    "# Splitting Data into Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnGSHd97tmLM"
   },
   "source": [
    "<br></br>\n",
    "After feature selection, we can now split the data into the training set and the test set by using the *train_test_split()* function from the *sklearn.model_selection* module. Typically the ratio of the size of the training set to the size of the test set is 80:20 so here we will follow this convention. This function returns four arrays listed below in order:\n",
    "- **X_train** : an array of values which represents the feature values for examples which are going to be used to train the model (part of the training set)\n",
    "- **X_test** : an array of values which represents the feature values for examples which are going to be used to test the accuracy of the model after it has been trained (part of the test set)\n",
    "- **y_train** : an array of values which represents the label values for examples which are going to be used to train the model (part of the training set)\n",
    "- **y_test** : an array of values which represents the label values for examples which are going to be used to test the accuracy of the model after it has been trained by comparing it to the model's predictions (part of the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6h38aAqGtmLN"
   },
   "outputs": [],
   "source": [
    "# first parameter is the (selected) feature values\n",
    "# second parameter is the label values\n",
    "# test_size parameter takes a float between 0 and 1, which represents the proportion of the test set to the entire dataset\n",
    "# random_state parameter takes in an int so that the output is reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2ZZaeEotmLO"
   },
   "source": [
    "We can check that the split was done correctly by printing the shape of X_train, the shape of X_test, and the proportion of data in the training set to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfb3U4E8tmLO",
    "outputId": "c675c388-924b-4108-8b3d-6aeff3892de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has 1065 rows and 8 columns\n",
      "X_test has 267 rows and 8 columns\n",
      "proportion of data in the X_test to the entire dataset: 0.20045045045045046\n"
     ]
    }
   ],
   "source": [
    "train_rows, train_cols = X_train.shape\n",
    "test_rows, test_cols = X_test.shape\n",
    "print(\"X_train has {} rows and {} columns\".format(train_rows, train_cols))\n",
    "print(\"X_test has {} rows and {} columns\".format(test_rows, test_cols))\n",
    "print(\"proportion of data in the X_test to the entire dataset:\", test_rows/essay_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dI4KfjOtmLP"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AubD1cyPtmLP"
   },
   "source": [
    "### &emsp;Difference between binary and multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFRsHfqAtmLQ"
   },
   "source": [
    "Classification refers to a predictive modeling problem that involves predicting a class label for some input data. Two of the most common types of these problems are binary and multi-class classification.\n",
    "\n",
    "In binary classification, there are only two class labels, therefore given some input data the model has to predict whether it is of some class X or not. For example, given an image the model has to predict whether it is a cat or not. It only requires one classifier model. (Band, 2020)\n",
    "\n",
    "Whereas in multi-class classification, there are multiple class labels, therefore, given some input data the model has to assign it to one of these labels. It might require more than one classifier model (Band, 2020). Since we have determined that the *score* column contains values that are categorical, and because there is more than two possible labels (scores can be one of [1,2,3,4,5,6]), in this case, predicting the score for an essay is an example of a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HycHqOitmLQ"
   },
   "source": [
    "# Normalization/Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYFsw2WdtmLQ"
   },
   "source": [
    "Normalization/Scaling is an important step in preprocessing as it changes the values in the numeric columns to a common scale while keeping the relative differences in the range of values (Jaitley, 2018). This is especially important when different features have vastly different ranges. For example, the *chars* column contains very large values when compared to the values in the *punctuations* column. The values in the *chars* column might then have a greater influence over the result due to its larger magnitude even though it might not necessarily be a better predictor than the values in the *punctuations* column. Therefore by normalizing the range of all features we can avoid this problem.\n",
    "\n",
    "Since we are working with features that have very different ranges (for example *chars* and *punctuations*) and we are planning to use an SVM, which assumes that the data provided is in a standard range, therefore normalization/scaling is required.\n",
    "\n",
    "Here we can use the *MinMaxScaler()* function from the *sklearn.preprocessing* module to scale each feature to the range [0,1]. Not only does the MinMaxScaler preserve the shape of the original distribution, it also avoids significantly altering the information embedded in the original data (Hale, 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p6LtH625tmLR"
   },
   "outputs": [],
   "source": [
    "# define the scaler we are going to use as the MinMaxScaler\n",
    "# we are going to scale the features to the default range of [0,1] since we have no negative values\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the scaler to the training data which computes the minimum and maximum of every feature in X_train\n",
    "# then we transform X_train to scale the data according to the computed minimum and maximum\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Here we transform X_test using the minimum and maximum of the corresponding features in X_train\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZuDmcEVtmLR"
   },
   "source": [
    "We can test this by printing out the maximum and minimum values for every feature in both the training and test sets. Note that while the minimum and maximum values of the features in the training set are 0s and 1s respectively, the minimum and maximum values of the features in the test set are not, with some of the maximum feature values exceeding 1. This is to be expected because the scaler was fitted according to the **training data** not the **test data**, what is important here is that the minimum and maximum feature values for the test set is still very close to the [0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKLWCSJotmLS",
    "outputId": "6fbd25e0-01fd-4899-efb5-d21bc13342de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum values for each feature in the training set: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Maximum values for each feature in the training set: [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Minimum values for each feature in the test set: [0.01709402 0.01571429 0.00070909 0.00032579 0.0018315  0.\n",
      " 0.         0.        ]\n",
      "Maximum values for each feature in the test set: [1.         1.         1.05885481 1.03691839 1.03846154 1.2405303\n",
      " 1.17006803 0.68055556]\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum values for each feature in the training set:\",X_train.min(axis=0))\n",
    "print(\"Maximum values for each feature in the training set:\", X_train.max(axis=0))\n",
    "print(\"Minimum values for each feature in the test set:\", X_test.min(axis=0))\n",
    "print(\"Maximum values for each feature in the test set:\", X_test.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YnRj0HLtmLT"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfInLRiftmLT"
   },
   "source": [
    "### &emsp;SVM in Relation to Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ys76Sqs-tmLU"
   },
   "source": [
    "Similar to Linear Regression, Support Vector Machines (SVMs) are supervised machine learning models. Whereas linear regression is typically used for regression problems, SVMs can be used for both classification *and* regression tasks (Gandhi, 2018). In regression tasks, the goal of linear regression is to minimize the sum of the squared errors, however the goal of the SVM (SVR) is to instead minimize the l2-norm of the coefficient vector, not the squared error which is instead handled in the constraints. This means that the SVM (SVR) gives us more flexibility as it allows us to ignore errors as long as they fall within an acceptable range/margin (Sharp, 2020).\n",
    "\n",
    "In classification tasks, the goal of an SVM algorithm is to find the optimal hyperplane that is able to best classify the input data. To this end, many hyperplanes are tested and the plane that has the maximum margin, i.e. the hyperplane that results in the maximum distance between the closest points from separate classes, is chosen (Gandhi, 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NGVYJZktmLU"
   },
   "source": [
    "### &emsp; Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5i8pKdWtmLU"
   },
   "source": [
    "Kernels or sometimes known as the \"kernel trick\" allows SVMs to create non-linear decision boundaries. These kernels are mathematical functions which takes input data in n dimensional space, which is not separable using a hyperplane, and transforms them into a higher dimension in which this data *is* separable. The resulting hyperplane can then be projected back down into n dimensional space to get a non-linear decision boundary (Suriya, n.d.). There are a couple of kernels for example linear, polynomial, radial basis function (rbf), and sigmoid but the most commonly used ones are linear and rbf (DataFlair, n.d.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9nOnMp8tmLV"
   },
   "source": [
    "### &emsp; Building the SVM (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1C0mnM8tmLV"
   },
   "source": [
    "Since I will be using SVM for classification, I will use the *SVC* (Support Vector Classification) class from the *sklearn.svm* module. In order to build a good model, we need to choose optimal parameters for the model. For the *SVC* class, the most important parameters are:\n",
    "- kernel: the type of kernel to be used in the algorithm\n",
    "- C: the regularization parameter which tells the algorithm how important misclassified points are\n",
    "- gamma: the kernel coefficient, it decides the level of influence of a single example\n",
    "\n",
    "Rather than randomly guessing values for the parameters, we can use the *GridSearchCV* class from the *sklearn.model_selection* module. GridSearchCV allows us to test every combination of the provided values for each of these parameters to find the parameters which result in the highest performing model when it is fitted to the training set.\n",
    "\n",
    "Here I allowed it to choose between two kernels - *linear* and *rbf*, as they are the most commonly used and reliable kernels, whereas for C and gamma I provided a wider range of values to test with.\n",
    "\n",
    "*Note that gamma is a parameter that is ignored by linear kernels therefore to reduce search time I only allowed GridSearchCV to test the different gamma values when the kernel being tested is the rbf kernel.*\n",
    "\n",
    "Running the code block below should only take ~10-30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lFezwrk-tmLV",
    "outputId": "e75de455-9652-4ff6-9f92-1194108557d5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "[CV 1/5; 1/35] START C=0.1, kernel=linear.......................................\n",
      "[CV 1/5; 1/35] END ........C=0.1, kernel=linear;, score=0.582 total time=   0.0s\n",
      "[CV 2/5; 1/35] START C=0.1, kernel=linear.......................................\n",
      "[CV 2/5; 1/35] END ........C=0.1, kernel=linear;, score=0.667 total time=   0.0s\n",
      "[CV 3/5; 1/35] START C=0.1, kernel=linear.......................................\n",
      "[CV 3/5; 1/35] END ........C=0.1, kernel=linear;, score=0.592 total time=   0.0s\n",
      "[CV 4/5; 1/35] START C=0.1, kernel=linear.......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/35] END ........C=0.1, kernel=linear;, score=0.629 total time=   0.0s\n",
      "[CV 5/5; 1/35] START C=0.1, kernel=linear.......................................\n",
      "[CV 5/5; 1/35] END ........C=0.1, kernel=linear;, score=0.582 total time=   0.0s\n",
      "[CV 1/5; 2/35] START C=1, kernel=linear.........................................\n",
      "[CV 1/5; 2/35] END ..........C=1, kernel=linear;, score=0.671 total time=   0.0s\n",
      "[CV 2/5; 2/35] START C=1, kernel=linear.........................................\n",
      "[CV 2/5; 2/35] END ..........C=1, kernel=linear;, score=0.709 total time=   0.0s\n",
      "[CV 3/5; 2/35] START C=1, kernel=linear.........................................\n",
      "[CV 3/5; 2/35] END ..........C=1, kernel=linear;, score=0.629 total time=   0.0s\n",
      "[CV 4/5; 2/35] START C=1, kernel=linear.........................................\n",
      "[CV 4/5; 2/35] END ..........C=1, kernel=linear;, score=0.671 total time=   0.1s\n",
      "[CV 5/5; 2/35] START C=1, kernel=linear.........................................\n",
      "[CV 5/5; 2/35] END ..........C=1, kernel=linear;, score=0.606 total time=   0.0s\n",
      "[CV 1/5; 3/35] START C=10, kernel=linear........................................\n",
      "[CV 1/5; 3/35] END .........C=10, kernel=linear;, score=0.671 total time=   0.0s\n",
      "[CV 2/5; 3/35] START C=10, kernel=linear........................................\n",
      "[CV 2/5; 3/35] END .........C=10, kernel=linear;, score=0.704 total time=   0.1s\n",
      "[CV 3/5; 3/35] START C=10, kernel=linear........................................\n",
      "[CV 3/5; 3/35] END .........C=10, kernel=linear;, score=0.629 total time=   0.1s\n",
      "[CV 4/5; 3/35] START C=10, kernel=linear........................................\n",
      "[CV 4/5; 3/35] END .........C=10, kernel=linear;, score=0.667 total time=   0.1s\n",
      "[CV 5/5; 3/35] START C=10, kernel=linear........................................\n",
      "[CV 5/5; 3/35] END .........C=10, kernel=linear;, score=0.634 total time=   0.1s\n",
      "[CV 1/5; 4/35] START C=100, kernel=linear.......................................\n",
      "[CV 1/5; 4/35] END ........C=100, kernel=linear;, score=0.648 total time=   0.1s\n",
      "[CV 2/5; 4/35] START C=100, kernel=linear.......................................\n",
      "[CV 2/5; 4/35] END ........C=100, kernel=linear;, score=0.718 total time=   0.1s\n",
      "[CV 3/5; 4/35] START C=100, kernel=linear.......................................\n",
      "[CV 3/5; 4/35] END ........C=100, kernel=linear;, score=0.643 total time=   0.1s\n",
      "[CV 4/5; 4/35] START C=100, kernel=linear.......................................\n",
      "[CV 4/5; 4/35] END ........C=100, kernel=linear;, score=0.671 total time=   0.1s\n",
      "[CV 5/5; 4/35] START C=100, kernel=linear.......................................\n",
      "[CV 5/5; 4/35] END ........C=100, kernel=linear;, score=0.620 total time=   0.1s\n",
      "[CV 1/5; 5/35] START C=1000, kernel=linear......................................\n",
      "[CV 1/5; 5/35] END .......C=1000, kernel=linear;, score=0.648 total time=   1.6s\n",
      "[CV 2/5; 5/35] START C=1000, kernel=linear......................................\n",
      "[CV 2/5; 5/35] END .......C=1000, kernel=linear;, score=0.718 total time=   0.8s\n",
      "[CV 3/5; 5/35] START C=1000, kernel=linear......................................\n",
      "[CV 3/5; 5/35] END .......C=1000, kernel=linear;, score=0.634 total time=   0.8s\n",
      "[CV 4/5; 5/35] START C=1000, kernel=linear......................................\n",
      "[CV 4/5; 5/35] END .......C=1000, kernel=linear;, score=0.671 total time=   0.2s\n",
      "[CV 5/5; 5/35] START C=1000, kernel=linear......................................\n",
      "[CV 5/5; 5/35] END .......C=1000, kernel=linear;, score=0.629 total time=   0.2s\n",
      "[CV 1/5; 6/35] START C=0.1, gamma=0.0001, kernel=rbf............................\n",
      "[CV 1/5; 6/35] END C=0.1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 2/5; 6/35] START C=0.1, gamma=0.0001, kernel=rbf............................\n",
      "[CV 2/5; 6/35] END C=0.1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 3/5; 6/35] START C=0.1, gamma=0.0001, kernel=rbf............................\n",
      "[CV 3/5; 6/35] END C=0.1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 4/5; 6/35] START C=0.1, gamma=0.0001, kernel=rbf............................\n",
      "[CV 4/5; 6/35] END C=0.1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 5/5; 6/35] START C=0.1, gamma=0.0001, kernel=rbf............................\n",
      "[CV 5/5; 6/35] END C=0.1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.1s\n",
      "[CV 1/5; 7/35] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 1/5; 7/35] END C=0.1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 2/5; 7/35] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 2/5; 7/35] END C=0.1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 3/5; 7/35] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 3/5; 7/35] END C=0.1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 4/5; 7/35] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 4/5; 7/35] END C=0.1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 5/5; 7/35] START C=0.1, gamma=0.001, kernel=rbf.............................\n",
      "[CV 5/5; 7/35] END C=0.1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 1/5; 8/35] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 1/5; 8/35] END C=0.1, gamma=0.01, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 2/5; 8/35] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 2/5; 8/35] END C=0.1, gamma=0.01, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 3/5; 8/35] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 3/5; 8/35] END C=0.1, gamma=0.01, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 4/5; 8/35] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 4/5; 8/35] END C=0.1, gamma=0.01, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 5/5; 8/35] START C=0.1, gamma=0.01, kernel=rbf..............................\n",
      "[CV 5/5; 8/35] END C=0.1, gamma=0.01, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 1/5; 9/35] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 1/5; 9/35] END C=0.1, gamma=0.1, kernel=rbf;, score=0.559 total time=   0.0s\n",
      "[CV 2/5; 9/35] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 2/5; 9/35] END C=0.1, gamma=0.1, kernel=rbf;, score=0.657 total time=   0.0s\n",
      "[CV 3/5; 9/35] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 3/5; 9/35] END C=0.1, gamma=0.1, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 4/5; 9/35] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 4/5; 9/35] END C=0.1, gamma=0.1, kernel=rbf;, score=0.601 total time=   0.0s\n",
      "[CV 5/5; 9/35] START C=0.1, gamma=0.1, kernel=rbf...............................\n",
      "[CV 5/5; 9/35] END C=0.1, gamma=0.1, kernel=rbf;, score=0.587 total time=   0.0s\n",
      "[CV 1/5; 10/35] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 1/5; 10/35] END .C=0.1, gamma=1, kernel=rbf;, score=0.596 total time=   0.0s\n",
      "[CV 2/5; 10/35] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 2/5; 10/35] END .C=0.1, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 3/5; 10/35] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 3/5; 10/35] END .C=0.1, gamma=1, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 4/5; 10/35] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 4/5; 10/35] END .C=0.1, gamma=1, kernel=rbf;, score=0.624 total time=   0.0s\n",
      "[CV 5/5; 10/35] START C=0.1, gamma=1, kernel=rbf................................\n",
      "[CV 5/5; 10/35] END .C=0.1, gamma=1, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 1/5; 11/35] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 1/5; 11/35] END C=0.1, gamma=10, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 2/5; 11/35] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 2/5; 11/35] END C=0.1, gamma=10, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 3/5; 11/35] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 3/5; 11/35] END C=0.1, gamma=10, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 4/5; 11/35] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 4/5; 11/35] END C=0.1, gamma=10, kernel=rbf;, score=0.653 total time=   0.1s\n",
      "[CV 5/5; 11/35] START C=0.1, gamma=10, kernel=rbf...............................\n",
      "[CV 5/5; 11/35] END C=0.1, gamma=10, kernel=rbf;, score=0.638 total time=   0.0s\n",
      "[CV 1/5; 12/35] START C=1, gamma=0.0001, kernel=rbf.............................\n",
      "[CV 1/5; 12/35] END C=1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 2/5; 12/35] START C=1, gamma=0.0001, kernel=rbf.............................\n",
      "[CV 2/5; 12/35] END C=1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.1s\n",
      "[CV 3/5; 12/35] START C=1, gamma=0.0001, kernel=rbf.............................\n",
      "[CV 3/5; 12/35] END C=1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 4/5; 12/35] START C=1, gamma=0.0001, kernel=rbf.............................\n",
      "[CV 4/5; 12/35] END C=1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 5/5; 12/35] START C=1, gamma=0.0001, kernel=rbf.............................\n",
      "[CV 5/5; 12/35] END C=1, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 1/5; 13/35] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 1/5; 13/35] END C=1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 2/5; 13/35] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 2/5; 13/35] END C=1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 3/5; 13/35] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 3/5; 13/35] END C=1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 4/5; 13/35] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 4/5; 13/35] END C=1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 5/5; 13/35] START C=1, gamma=0.001, kernel=rbf..............................\n",
      "[CV 5/5; 13/35] END C=1, gamma=0.001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 1/5; 14/35] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 1/5; 14/35] END C=1, gamma=0.01, kernel=rbf;, score=0.563 total time=   0.0s\n",
      "[CV 2/5; 14/35] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 2/5; 14/35] END C=1, gamma=0.01, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 3/5; 14/35] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 3/5; 14/35] END C=1, gamma=0.01, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 4/5; 14/35] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 4/5; 14/35] END C=1, gamma=0.01, kernel=rbf;, score=0.601 total time=   0.0s\n",
      "[CV 5/5; 14/35] START C=1, gamma=0.01, kernel=rbf...............................\n",
      "[CV 5/5; 14/35] END C=1, gamma=0.01, kernel=rbf;, score=0.587 total time=   0.0s\n",
      "[CV 1/5; 15/35] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 1/5; 15/35] END .C=1, gamma=0.1, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 2/5; 15/35] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 2/5; 15/35] END .C=1, gamma=0.1, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 3/5; 15/35] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 3/5; 15/35] END .C=1, gamma=0.1, kernel=rbf;, score=0.601 total time=   0.0s\n",
      "[CV 4/5; 15/35] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 4/5; 15/35] END .C=1, gamma=0.1, kernel=rbf;, score=0.610 total time=   0.0s\n",
      "[CV 5/5; 15/35] START C=1, gamma=0.1, kernel=rbf................................\n",
      "[CV 5/5; 15/35] END .C=1, gamma=0.1, kernel=rbf;, score=0.592 total time=   0.0s\n",
      "[CV 1/5; 16/35] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 1/5; 16/35] END ...C=1, gamma=1, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 2/5; 16/35] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 2/5; 16/35] END ...C=1, gamma=1, kernel=rbf;, score=0.695 total time=   0.0s\n",
      "[CV 3/5; 16/35] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 3/5; 16/35] END ...C=1, gamma=1, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5; 16/35] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 4/5; 16/35] END ...C=1, gamma=1, kernel=rbf;, score=0.657 total time=   0.1s\n",
      "[CV 5/5; 16/35] START C=1, gamma=1, kernel=rbf..................................\n",
      "[CV 5/5; 16/35] END ...C=1, gamma=1, kernel=rbf;, score=0.629 total time=   0.0s\n",
      "[CV 1/5; 17/35] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 1/5; 17/35] END ..C=1, gamma=10, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 2/5; 17/35] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 2/5; 17/35] END ..C=1, gamma=10, kernel=rbf;, score=0.685 total time=   0.0s\n",
      "[CV 3/5; 17/35] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 3/5; 17/35] END ..C=1, gamma=10, kernel=rbf;, score=0.653 total time=   0.0s\n",
      "[CV 4/5; 17/35] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 4/5; 17/35] END ..C=1, gamma=10, kernel=rbf;, score=0.657 total time=   0.0s\n",
      "[CV 5/5; 17/35] START C=1, gamma=10, kernel=rbf.................................\n",
      "[CV 5/5; 17/35] END ..C=1, gamma=10, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 1/5; 18/35] START C=10, gamma=0.0001, kernel=rbf............................\n",
      "[CV 1/5; 18/35] END C=10, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 2/5; 18/35] START C=10, gamma=0.0001, kernel=rbf............................\n",
      "[CV 2/5; 18/35] END C=10, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 3/5; 18/35] START C=10, gamma=0.0001, kernel=rbf............................\n",
      "[CV 3/5; 18/35] END C=10, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 4/5; 18/35] START C=10, gamma=0.0001, kernel=rbf............................\n",
      "[CV 4/5; 18/35] END C=10, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 5/5; 18/35] START C=10, gamma=0.0001, kernel=rbf............................\n",
      "[CV 5/5; 18/35] END C=10, gamma=0.0001, kernel=rbf;, score=0.432 total time=   0.0s\n",
      "[CV 1/5; 19/35] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 1/5; 19/35] END C=10, gamma=0.001, kernel=rbf;, score=0.563 total time=   0.0s\n",
      "[CV 2/5; 19/35] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 2/5; 19/35] END C=10, gamma=0.001, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 3/5; 19/35] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 3/5; 19/35] END C=10, gamma=0.001, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 4/5; 19/35] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 4/5; 19/35] END C=10, gamma=0.001, kernel=rbf;, score=0.601 total time=   0.0s\n",
      "[CV 5/5; 19/35] START C=10, gamma=0.001, kernel=rbf.............................\n",
      "[CV 5/5; 19/35] END C=10, gamma=0.001, kernel=rbf;, score=0.587 total time=   0.0s\n",
      "[CV 1/5; 20/35] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 1/5; 20/35] END C=10, gamma=0.01, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 2/5; 20/35] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 2/5; 20/35] END C=10, gamma=0.01, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 3/5; 20/35] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 3/5; 20/35] END C=10, gamma=0.01, kernel=rbf;, score=0.596 total time=   0.0s\n",
      "[CV 4/5; 20/35] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 4/5; 20/35] END C=10, gamma=0.01, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 5/5; 20/35] START C=10, gamma=0.01, kernel=rbf..............................\n",
      "[CV 5/5; 20/35] END C=10, gamma=0.01, kernel=rbf;, score=0.587 total time=   0.0s\n",
      "[CV 1/5; 21/35] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 1/5; 21/35] END C=10, gamma=0.1, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 2/5; 21/35] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 2/5; 21/35] END C=10, gamma=0.1, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 3/5; 21/35] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 3/5; 21/35] END C=10, gamma=0.1, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5; 21/35] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 4/5; 21/35] END C=10, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.1s\n",
      "[CV 5/5; 21/35] START C=10, gamma=0.1, kernel=rbf...............................\n",
      "[CV 5/5; 21/35] END C=10, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 1/5; 22/35] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 1/5; 22/35] END ..C=10, gamma=1, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 2/5; 22/35] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 2/5; 22/35] END ..C=10, gamma=1, kernel=rbf;, score=0.690 total time=   0.0s\n",
      "[CV 3/5; 22/35] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 3/5; 22/35] END ..C=10, gamma=1, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5; 22/35] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 4/5; 22/35] END ..C=10, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5; 22/35] START C=10, gamma=1, kernel=rbf.................................\n",
      "[CV 5/5; 22/35] END ..C=10, gamma=1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 1/5; 23/35] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 1/5; 23/35] END .C=10, gamma=10, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 2/5; 23/35] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 2/5; 23/35] END .C=10, gamma=10, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 3/5; 23/35] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 3/5; 23/35] END .C=10, gamma=10, kernel=rbf;, score=0.653 total time=   0.0s\n",
      "[CV 4/5; 23/35] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 4/5; 23/35] END .C=10, gamma=10, kernel=rbf;, score=0.676 total time=   0.1s\n",
      "[CV 5/5; 23/35] START C=10, gamma=10, kernel=rbf................................\n",
      "[CV 5/5; 23/35] END .C=10, gamma=10, kernel=rbf;, score=0.587 total time=   0.0s\n",
      "[CV 1/5; 24/35] START C=100, gamma=0.0001, kernel=rbf...........................\n",
      "[CV 1/5; 24/35] END C=100, gamma=0.0001, kernel=rbf;, score=0.563 total time=   0.0s\n",
      "[CV 2/5; 24/35] START C=100, gamma=0.0001, kernel=rbf...........................\n",
      "[CV 2/5; 24/35] END C=100, gamma=0.0001, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 3/5; 24/35] START C=100, gamma=0.0001, kernel=rbf...........................\n",
      "[CV 3/5; 24/35] END C=100, gamma=0.0001, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 4/5; 24/35] START C=100, gamma=0.0001, kernel=rbf...........................\n",
      "[CV 4/5; 24/35] END C=100, gamma=0.0001, kernel=rbf;, score=0.601 total time=   0.0s\n",
      "[CV 5/5; 24/35] START C=100, gamma=0.0001, kernel=rbf...........................\n",
      "[CV 5/5; 24/35] END C=100, gamma=0.0001, kernel=rbf;, score=0.587 total time=   0.0s\n",
      "[CV 1/5; 25/35] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 1/5; 25/35] END C=100, gamma=0.001, kernel=rbf;, score=0.606 total time=   0.0s\n",
      "[CV 2/5; 25/35] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 2/5; 25/35] END C=100, gamma=0.001, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 3/5; 25/35] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 3/5; 25/35] END C=100, gamma=0.001, kernel=rbf;, score=0.596 total time=   0.0s\n",
      "[CV 4/5; 25/35] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 4/5; 25/35] END C=100, gamma=0.001, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 5/5; 25/35] START C=100, gamma=0.001, kernel=rbf............................\n",
      "[CV 5/5; 25/35] END C=100, gamma=0.001, kernel=rbf;, score=0.577 total time=   0.0s\n",
      "[CV 1/5; 26/35] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 1/5; 26/35] END C=100, gamma=0.01, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 2/5; 26/35] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 2/5; 26/35] END C=100, gamma=0.01, kernel=rbf;, score=0.709 total time=   0.0s\n",
      "[CV 3/5; 26/35] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 3/5; 26/35] END C=100, gamma=0.01, kernel=rbf;, score=0.624 total time=   0.1s\n",
      "[CV 4/5; 26/35] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 4/5; 26/35] END C=100, gamma=0.01, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 5/5; 26/35] START C=100, gamma=0.01, kernel=rbf.............................\n",
      "[CV 5/5; 26/35] END C=100, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 1/5; 27/35] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 1/5; 27/35] END C=100, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 2/5; 27/35] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 2/5; 27/35] END C=100, gamma=0.1, kernel=rbf;, score=0.681 total time=   0.0s\n",
      "[CV 3/5; 27/35] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 3/5; 27/35] END C=100, gamma=0.1, kernel=rbf;, score=0.653 total time=   0.0s\n",
      "[CV 4/5; 27/35] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 4/5; 27/35] END C=100, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5; 27/35] START C=100, gamma=0.1, kernel=rbf..............................\n",
      "[CV 5/5; 27/35] END C=100, gamma=0.1, kernel=rbf;, score=0.624 total time=   0.0s\n",
      "[CV 1/5; 28/35] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 1/5; 28/35] END .C=100, gamma=1, kernel=rbf;, score=0.709 total time=   0.1s\n",
      "[CV 2/5; 28/35] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 2/5; 28/35] END .C=100, gamma=1, kernel=rbf;, score=0.690 total time=   0.1s\n",
      "[CV 3/5; 28/35] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 3/5; 28/35] END .C=100, gamma=1, kernel=rbf;, score=0.667 total time=   0.1s\n",
      "[CV 4/5; 28/35] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 4/5; 28/35] END .C=100, gamma=1, kernel=rbf;, score=0.685 total time=   0.1s\n",
      "[CV 5/5; 28/35] START C=100, gamma=1, kernel=rbf................................\n",
      "[CV 5/5; 28/35] END .C=100, gamma=1, kernel=rbf;, score=0.606 total time=   0.1s\n",
      "[CV 1/5; 29/35] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 1/5; 29/35] END C=100, gamma=10, kernel=rbf;, score=0.657 total time=   0.1s\n",
      "[CV 2/5; 29/35] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 2/5; 29/35] END C=100, gamma=10, kernel=rbf;, score=0.634 total time=   0.1s\n",
      "[CV 3/5; 29/35] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 3/5; 29/35] END C=100, gamma=10, kernel=rbf;, score=0.624 total time=   0.1s\n",
      "[CV 4/5; 29/35] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 4/5; 29/35] END C=100, gamma=10, kernel=rbf;, score=0.648 total time=   0.1s\n",
      "[CV 5/5; 29/35] START C=100, gamma=10, kernel=rbf...............................\n",
      "[CV 5/5; 29/35] END C=100, gamma=10, kernel=rbf;, score=0.587 total time=   0.1s\n",
      "[CV 1/5; 30/35] START C=1000, gamma=0.0001, kernel=rbf..........................\n",
      "[CV 1/5; 30/35] END C=1000, gamma=0.0001, kernel=rbf;, score=0.606 total time=   0.1s\n",
      "[CV 2/5; 30/35] START C=1000, gamma=0.0001, kernel=rbf..........................\n",
      "[CV 2/5; 30/35] END C=1000, gamma=0.0001, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 3/5; 30/35] START C=1000, gamma=0.0001, kernel=rbf..........................\n",
      "[CV 3/5; 30/35] END C=1000, gamma=0.0001, kernel=rbf;, score=0.596 total time=   0.0s\n",
      "[CV 4/5; 30/35] START C=1000, gamma=0.0001, kernel=rbf..........................\n",
      "[CV 4/5; 30/35] END C=1000, gamma=0.0001, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 5/5; 30/35] START C=1000, gamma=0.0001, kernel=rbf..........................\n",
      "[CV 5/5; 30/35] END C=1000, gamma=0.0001, kernel=rbf;, score=0.577 total time=   0.0s\n",
      "[CV 1/5; 31/35] START C=1000, gamma=0.001, kernel=rbf...........................\n",
      "[CV 1/5; 31/35] END C=1000, gamma=0.001, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 2/5; 31/35] START C=1000, gamma=0.001, kernel=rbf...........................\n",
      "[CV 2/5; 31/35] END C=1000, gamma=0.001, kernel=rbf;, score=0.723 total time=   0.0s\n",
      "[CV 3/5; 31/35] START C=1000, gamma=0.001, kernel=rbf...........................\n",
      "[CV 3/5; 31/35] END C=1000, gamma=0.001, kernel=rbf;, score=0.629 total time=   0.0s\n",
      "[CV 4/5; 31/35] START C=1000, gamma=0.001, kernel=rbf...........................\n",
      "[CV 4/5; 31/35] END C=1000, gamma=0.001, kernel=rbf;, score=0.657 total time=   0.0s\n",
      "[CV 5/5; 31/35] START C=1000, gamma=0.001, kernel=rbf...........................\n",
      "[CV 5/5; 31/35] END C=1000, gamma=0.001, kernel=rbf;, score=0.610 total time=   0.0s\n",
      "[CV 1/5; 32/35] START C=1000, gamma=0.01, kernel=rbf............................\n",
      "[CV 1/5; 32/35] END C=1000, gamma=0.01, kernel=rbf;, score=0.657 total time=   0.1s\n",
      "[CV 2/5; 32/35] START C=1000, gamma=0.01, kernel=rbf............................\n",
      "[CV 2/5; 32/35] END C=1000, gamma=0.01, kernel=rbf;, score=0.695 total time=   0.0s\n",
      "[CV 3/5; 32/35] START C=1000, gamma=0.01, kernel=rbf............................\n",
      "[CV 3/5; 32/35] END C=1000, gamma=0.01, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5; 32/35] START C=1000, gamma=0.01, kernel=rbf............................\n",
      "[CV 4/5; 32/35] END C=1000, gamma=0.01, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 5/5; 32/35] START C=1000, gamma=0.01, kernel=rbf............................\n",
      "[CV 5/5; 32/35] END C=1000, gamma=0.01, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 1/5; 33/35] START C=1000, gamma=0.1, kernel=rbf.............................\n",
      "[CV 1/5; 33/35] END C=1000, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.1s\n",
      "[CV 2/5; 33/35] START C=1000, gamma=0.1, kernel=rbf.............................\n",
      "[CV 2/5; 33/35] END C=1000, gamma=0.1, kernel=rbf;, score=0.676 total time=   0.1s\n",
      "[CV 3/5; 33/35] START C=1000, gamma=0.1, kernel=rbf.............................\n",
      "[CV 3/5; 33/35] END C=1000, gamma=0.1, kernel=rbf;, score=0.662 total time=   0.1s\n",
      "[CV 4/5; 33/35] START C=1000, gamma=0.1, kernel=rbf.............................\n",
      "[CV 4/5; 33/35] END C=1000, gamma=0.1, kernel=rbf;, score=0.690 total time=   0.1s\n",
      "[CV 5/5; 33/35] START C=1000, gamma=0.1, kernel=rbf.............................\n",
      "[CV 5/5; 33/35] END C=1000, gamma=0.1, kernel=rbf;, score=0.606 total time=   0.1s\n",
      "[CV 1/5; 34/35] START C=1000, gamma=1, kernel=rbf...............................\n",
      "[CV 1/5; 34/35] END C=1000, gamma=1, kernel=rbf;, score=0.681 total time=   0.2s\n",
      "[CV 2/5; 34/35] START C=1000, gamma=1, kernel=rbf...............................\n",
      "[CV 2/5; 34/35] END C=1000, gamma=1, kernel=rbf;, score=0.723 total time=   0.1s\n",
      "[CV 3/5; 34/35] START C=1000, gamma=1, kernel=rbf...............................\n",
      "[CV 3/5; 34/35] END C=1000, gamma=1, kernel=rbf;, score=0.662 total time=   0.2s\n",
      "[CV 4/5; 34/35] START C=1000, gamma=1, kernel=rbf...............................\n",
      "[CV 4/5; 34/35] END C=1000, gamma=1, kernel=rbf;, score=0.718 total time=   0.2s\n",
      "[CV 5/5; 34/35] START C=1000, gamma=1, kernel=rbf...............................\n",
      "[CV 5/5; 34/35] END C=1000, gamma=1, kernel=rbf;, score=0.606 total time=   0.2s\n",
      "[CV 1/5; 35/35] START C=1000, gamma=10, kernel=rbf..............................\n",
      "[CV 1/5; 35/35] END C=1000, gamma=10, kernel=rbf;, score=0.606 total time=   0.6s\n",
      "[CV 2/5; 35/35] START C=1000, gamma=10, kernel=rbf..............................\n",
      "[CV 2/5; 35/35] END C=1000, gamma=10, kernel=rbf;, score=0.657 total time=   0.5s\n",
      "[CV 3/5; 35/35] START C=1000, gamma=10, kernel=rbf..............................\n",
      "[CV 3/5; 35/35] END C=1000, gamma=10, kernel=rbf;, score=0.596 total time=   0.5s\n",
      "[CV 4/5; 35/35] START C=1000, gamma=10, kernel=rbf..............................\n",
      "[CV 4/5; 35/35] END C=1000, gamma=10, kernel=rbf;, score=0.629 total time=   0.5s\n",
      "[CV 5/5; 35/35] START C=1000, gamma=10, kernel=rbf..............................\n",
      "[CV 5/5; 35/35] END C=1000, gamma=10, kernel=rbf;, score=0.577 total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(random_state=42),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.1, 1, 10, 100, 1000], &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "                         {&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;gamma&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=SVC(random_state=42),\n",
       "             param_grid=[{&#x27;C&#x27;: [0.1, 1, 10, 100, 1000], &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "                         {&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                          &#x27;gamma&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "             verbose=10)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1000, gamma=1, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1000, gamma=1, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(random_state=42),\n",
       "             param_grid=[{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
       "                         {'C': [0.1, 1, 10, 100, 1000],\n",
       "                          'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "                          'kernel': ['rbf']}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the SVC\n",
    "# provide an integer for random_state so that the output is reproducible\n",
    "svm = SVC(random_state = 42)\n",
    "\n",
    "# lists the possible values for the 3 important parameters - kernel, C, and gamma\n",
    "parameters = [\n",
    "    {'C' : [0.1, 1, 10, 100, 1000], 'kernel' : ['linear']},\n",
    "    {'C' : [0.1, 1, 10, 100, 1000], 'gamma' : [0.0001, 0.001, 0.01, 0.1, 1, 10], 'kernel' : [ 'rbf']}\n",
    "]\n",
    "\n",
    "# in the first parameter the estimator for which we want to test out the parameter combinations is passed in\n",
    "# In the second parameter, try every combination of parameter values for the provided estimator (svm)\n",
    "# verbose parameter controls its verbosity, a value of 1 just displays the total number of combinations\n",
    "opt_svm = GridSearchCV(svm, parameters, verbose=10)\n",
    "\n",
    "# fit the svm to the training set and try all the parameter combinations to find the best one\n",
    "opt_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5XvuE7ltmLW"
   },
   "source": [
    "After the model has been fitted to the training set and the best parameters have been chosen, we can see which of the parameter values had the best result by accessing the *best_params_* attribute of GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X53puApotmLW",
    "outputId": "212e4e81-852e-4f7e-8b00-a676e6b8c800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMFFNdWxtmLX"
   },
   "source": [
    "From this we can see that among the provided values for each parameter, a C value of 1000, a gamma of 1, and an rbf kernel performed the best with the given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrjbV7FltmLX"
   },
   "source": [
    "### &emsp;Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gG_13KVHtmLY"
   },
   "source": [
    "Now that we have a trained SVM model, we can use it to predict the scores for the essays in the training set. We can do this by calling the *.predict()* function of the trained model and passing in the feature values of the essays in the test set. This results in an array of predicted scores for each of the essays in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1PLM43SYtmLY"
   },
   "outputs": [],
   "source": [
    "# get the predictions of the essays in the test set\n",
    "predictions = opt_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruHW79V2tmLY"
   },
   "source": [
    "We can look at the predictions by simply printing out the *predictions* array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0rOQm8KtmLZ",
    "outputId": "360df3ba-92c8-478f-a07c-041e65fef17f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 3, 2, 3, 4, 3, 4, 2, 3, 4, 3, 3, 3, 4, 3, 4, 3, 3, 3, 4, 3,\n",
       "       3, 4, 3, 4, 4, 3, 3, 4, 4, 4, 3, 4, 3, 3, 4, 3, 4, 3, 2, 4, 4, 4,\n",
       "       4, 3, 3, 2, 4, 3, 4, 3, 4, 4, 4, 2, 4, 3, 4, 4, 4, 3, 5, 4, 3, 5,\n",
       "       3, 4, 3, 3, 3, 4, 3, 2, 4, 3, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4,\n",
       "       2, 3, 4, 3, 4, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3,\n",
       "       4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3, 2, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4,\n",
       "       4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3, 4, 3,\n",
       "       3, 1, 4, 4, 2, 3, 4, 3, 4, 2, 3, 4, 3, 3, 4, 3, 4, 3, 4, 3, 4, 4,\n",
       "       3, 4, 3, 4, 3, 3, 2, 3, 3, 4, 4, 3, 3, 2, 3, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 4, 4, 2, 3,\n",
       "       3, 3, 4, 3, 4, 3, 3, 3, 3, 2, 3, 4, 4, 4, 4, 3, 4, 4, 3, 3, 4, 4,\n",
       "       2, 4, 4, 4, 4, 3, 2, 3, 3, 3, 4, 3, 4, 4, 4, 1, 3, 3, 4, 3, 3, 4,\n",
       "       3, 4, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26ryucgLtmLZ"
   },
   "source": [
    "To confirm that they are valid scores/predictions we can find the minimum and maximum score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTBUsWKstmLa",
    "outputId": "5fa070ff-8200-47aa-be42-2110f3ada5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum score predicted:  1\n",
      "Maximum score predicted:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum score predicted: \", predictions.min())\n",
    "print(\"Maximum score predicted: \", predictions.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trE7qqyxtmLb"
   },
   "source": [
    "We can see that indeed the array consists of integers between 1 to 5 which is within the range of possible scores (1 to 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkspAHDTtmLb"
   },
   "source": [
    "# Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "133WbQgVtmLb"
   },
   "source": [
    "### &emsp;Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A40M4GE1tmLc"
   },
   "source": [
    "Since we are evaluating a classification model, we can use a confusion matrix which allows for the visualization of the model's performance by displaying a grid of the predicted labels against the actual labels.\n",
    "\n",
    "The first step is to compute the confusion matrix using the *confusion_matrix()* function from the *sklearn.metrics* module and pass in the actual labels along with the predicted labels. Then we can use the *ConfusionMatrixDisplay* class from the same module for the visual representation of this confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "-iXJw3fwtmLc",
    "outputId": "582dcef0-5add-48f9-ca6b-1a6293ad811d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x79d3d8d585e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix using the actual scores of the essays in the test set and the model predictions\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "# first parameter is the confusion matrix computed\n",
    "# display_labels parameter defines the list of possible labels (from 1 to 6), since essay scores range from 1-6\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[1,2,3,4,5,6])\n",
    "\n",
    "# display the confusion matrix\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMxJ3OS9tmLd"
   },
   "source": [
    "In the confusion matrix, the value in row i column j represents the number of essays for which the model predicted a score of j but actually has a score of i. For example, the value in row 1 column 2 is 3. This means that there are 3 essays for which the model predicted a score of 2 but in actuality, they had a score of 1.\n",
    "\n",
    "The most important thing to notice in the grid above are the values in the diagonal from the upper left to the lower right as they represent the number of predictions that are correct, the brighter the square the higher the frequency. Ideally this diagonal should be lit up. Notice here that aside from row 3 column 3, and row 4 column 4, all the other squares on this diagonal are quite dark however this does not necessarily mean that the model's performance is poor, in this case it simply means that there are comparably few essays with scores less than 3 or more than 4. For example, if we total up the values in row 6 we can see that there is only 1 essay that has a score of 6!\n",
    "\n",
    "Of course this means that values *not* on the diagonal should ideally be very dark as they represent wrong predictions.\n",
    "\n",
    "Therefore since the (middle of the) diagonal is well-lit and the squares that are *not* on the diagonal are mostly dark we can get some sense that the model's performance is quite good. We can reinforce this by testing the model with the QWK metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7S-lvTPtmLe"
   },
   "source": [
    "### &emsp;&emsp;QWK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk3ZRiKCtmLf"
   },
   "source": [
    "The Quadratic Weighted Kappa (QWK) is a metric that is used to evaluate the amount of agreement between the model or algorithm's predictions and the actual labels and tries to account for random chance by adjusting for the probability that the model's prediction agrees with the actual label \"by chance\". It does this by assuming that there is a predetermined proportion of objects assigned to each label. Most notably this metric is used to score submissions on *kaggle* (Arora, 2019).\n",
    "\n",
    "The possible scores resulting from this metric ranges from a minimum of -1.0 to a maximum score of 1.0, and the aim is to get as close to 1.0 as possible (Arora, 2019).\n",
    "\n",
    "We can compute the Quadratic Weighted Kappa metric by using the *cohen_kappa_score()* function in the *sklearn.metrics* module with the *weights* parameter set as 'quadratic'. In the code block below we are comparing the model's predictions with the actual scores (labels) to compute a score denoting the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDrIyfu-tmLf",
    "outputId": "4a6937ae-a741-41c6-e3f9-e8445c8d6903"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133519059590949"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the QWK for the model predictions\n",
    "cohen_kappa_score(y_test, predictions, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG0SyfWEtmLh"
   },
   "source": [
    "The highest possible score is 1.0 which denotes that the model's predictions are exactly the same as the actual labels, a score of 0.0 indicates that the model's predictions which do agree with the actual labels simply match \"by chance\". On the other hand, a score of -1.0 indicates that the model's predictions are as far away as possible from the actual labels (Arora, 2019).\n",
    "\n",
    "Typically, a score of 0.6+ is considered very good (Arora, 2019), therefore since we can see from the output of the code above that our model has a score of 0.71 we can now be confident that it is quite a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wbvlR5rtmLj"
   },
   "source": [
    "## &emsp; Using the SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1iWRYbjtmLj"
   },
   "source": [
    "Here I used the SVM model to output the predictions of the unlabeled data *'essay_features.csv'* into a formatted CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCuErFd-tmLk"
   },
   "source": [
    "### &emsp; Reading File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk2wrW2ttmLl"
   },
   "source": [
    "First we need to read the *'essay_features.csv'* file and convert it to a DataFrame by using the *.read_csv()* function from the *pandas* library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "h2EP3nBFtmLm"
   },
   "outputs": [],
   "source": [
    "kaggle_data = pd.read_csv('/content/sample_data/essay_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWFLuUehtmLn"
   },
   "source": [
    "We can display the data that we have read to get a glimpse at the data. The most notable thing here is that it differs from the original dataset as it is missing the score column, this is because we are meant to fill this column with the predictions of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "4UdI9UMbtmLo",
    "outputId": "b920a730-c703-437e-fd34-5eb01b1fff8a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"kaggle_data\",\n  \"rows\": 1332,\n  \"fields\": [\n    {\n      \"column\": \"essayid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 526,\n        \"min\": 0,\n        \"max\": 1799,\n        \"num_unique_values\": 1332,\n        \"samples\": [\n          163,\n          1194,\n          196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 865,\n        \"min\": 169,\n        \"max\": 6142,\n        \"num_unique_values\": 1064,\n        \"samples\": [\n          1985,\n          1781,\n          6142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 171,\n        \"min\": 36,\n        \"max\": 1170,\n        \"num_unique_values\": 580,\n        \"samples\": [\n          58,\n          488,\n          415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"commas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 72,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          14,\n          10,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"apostrophes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2,\n        \"max\": 51,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          27,\n          3,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"punctuations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          0,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23107146022809866,\n        \"min\": 2.231321839,\n        \"max\": 5.6814285710000005,\n        \"num_unique_values\": 1302,\n        \"samples\": [\n          5.195826645,\n          4.971509972,\n          5.054176072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 642,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          20,\n          52,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          17,\n          10,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.160020046143805,\n        \"min\": 1.08411215,\n        \"max\": 303.0,\n        \"num_unique_values\": 1068,\n        \"samples\": [\n          20.1,\n          34.58823529,\n          33.52631579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170.98511051781273,\n        \"min\": 35.64705882,\n        \"max\": 1158.984563,\n        \"num_unique_values\": 1208,\n        \"samples\": [\n          450.9911308,\n          639.6500778,\n          168.98809519999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007308354612039425,\n        \"min\": 0.924771388,\n        \"max\": 1.0,\n        \"num_unique_values\": 1263,\n        \"samples\": [\n          0.982283775,\n          0.988599957,\n          0.990954591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 82,\n        \"min\": 14,\n        \"max\": 669,\n        \"num_unique_values\": 341,\n        \"samples\": [\n          344,\n          25,\n          264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.052466048998499465,\n        \"min\": 0.288888889,\n        \"max\": 0.961206897,\n        \"num_unique_values\": 1225,\n        \"samples\": [\n          0.487179487,\n          0.436399217,\n          0.4441558439999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43,\n        \"min\": 11,\n        \"max\": 355,\n        \"num_unique_values\": 216,\n        \"samples\": [\n          186,\n          28,\n          156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonym_words/total_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038870417437443114,\n        \"min\": 0.027298851,\n        \"max\": 0.465517241,\n        \"num_unique_values\": 1223,\n        \"samples\": [\n          0.256684492,\n          0.225641026,\n          0.241167435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unstemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159,\n        \"min\": 48,\n        \"max\": 750,\n        \"num_unique_values\": 509,\n        \"samples\": [\n          582,\n          169,\n          597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155,\n        \"min\": 50,\n        \"max\": 750,\n        \"num_unique_values\": 510,\n        \"samples\": [\n          244,\n          474,\n          666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "kaggle_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-819daa14-df7d-445e-90da-bc1a7cef8e6a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>2153</td>\n",
       "      <td>426</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.053991</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>423.995272</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>207</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>105</td>\n",
       "      <td>0.246479</td>\n",
       "      <td>424</td>\n",
       "      <td>412</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>1480</td>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.068493</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>26.545455</td>\n",
       "      <td>290.993103</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>148</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>77</td>\n",
       "      <td>0.263699</td>\n",
       "      <td>356</td>\n",
       "      <td>345</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>3964</td>\n",
       "      <td>849</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4.669022</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17.326531</td>\n",
       "      <td>843.990544</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>285</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>130</td>\n",
       "      <td>0.153121</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>988</td>\n",
       "      <td>210</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704762</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>207.653784</td>\n",
       "      <td>0.988828</td>\n",
       "      <td>112</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>62</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>217</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>3139</td>\n",
       "      <td>600</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.231667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>594.652150</td>\n",
       "      <td>0.991087</td>\n",
       "      <td>255</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>165</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>702</td>\n",
       "      <td>677</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>2404</td>\n",
       "      <td>467</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.147752</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21.227273</td>\n",
       "      <td>462.987069</td>\n",
       "      <td>0.991407</td>\n",
       "      <td>200</td>\n",
       "      <td>0.428266</td>\n",
       "      <td>113</td>\n",
       "      <td>0.241970</td>\n",
       "      <td>529</td>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>1182</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4.904564</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>238.655462</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>94</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>67</td>\n",
       "      <td>0.278008</td>\n",
       "      <td>293</td>\n",
       "      <td>283</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>1814</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.997245</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>27.923077</td>\n",
       "      <td>362.329640</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>170</td>\n",
       "      <td>0.468320</td>\n",
       "      <td>107</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>427</td>\n",
       "      <td>415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>1427</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.972125</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22.076923</td>\n",
       "      <td>284.657277</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>144</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>83</td>\n",
       "      <td>0.289199</td>\n",
       "      <td>323</td>\n",
       "      <td>312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>2806</td>\n",
       "      <td>542</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.177122</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24.636364</td>\n",
       "      <td>538.988889</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>284</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>155</td>\n",
       "      <td>0.285978</td>\n",
       "      <td>596</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows  19 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-819daa14-df7d-445e-90da-bc1a7cef8e6a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-819daa14-df7d-445e-90da-bc1a7cef8e6a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-819daa14-df7d-445e-90da-bc1a7cef8e6a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-91b4f597-eeff-478e-890d-dfbbf7b0249f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91b4f597-eeff-478e-890d-dfbbf7b0249f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-91b4f597-eeff-478e-890d-dfbbf7b0249f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_5f715292-08d2-49c4-98e4-7436a16a816c\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('kaggle_data')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_5f715292-08d2-49c4-98e4-7436a16a816c button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('kaggle_data');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      essayid  chars  words  commas  apostrophes  punctuations  \\\n",
       "0        1457   2153    426      14            6             0   \n",
       "1         503   1480    292       9            7             0   \n",
       "2         253   3964    849      19           26             1   \n",
       "3         107    988    210       8            7             0   \n",
       "4        1450   3139    600      13            8             0   \n",
       "...       ...    ...    ...     ...          ...           ...   \n",
       "1327     1151   2404    467      16           10             0   \n",
       "1328     1015   1182    241       0           14             0   \n",
       "1329     1345   1814    363       5           11             0   \n",
       "1330      344   1427    287       5            8             0   \n",
       "1331     1077   2806    542      24            6             0   \n",
       "\n",
       "      avg_word_length  sentences  questions  avg_word_sentence         POS  \\\n",
       "0            5.053991         16          0          26.625000  423.995272   \n",
       "1            5.068493         11          0          26.545455  290.993103   \n",
       "2            4.669022         49          2          17.326531  843.990544   \n",
       "3            4.704762         12          0          17.500000  207.653784   \n",
       "4            5.231667         24          1          25.000000  594.652150   \n",
       "...               ...        ...        ...                ...         ...   \n",
       "1327         5.147752         22          0          21.227273  462.987069   \n",
       "1328         4.904564         16          0          15.062500  238.655462   \n",
       "1329         4.997245         13          3          27.923077  362.329640   \n",
       "1330         4.972125         13          1          22.076923  284.657277   \n",
       "1331         5.177122         22          3          24.636364  538.988889   \n",
       "\n",
       "      POS/total_words  prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0            0.995294           207                  0.485915            105   \n",
       "1            0.996552           148                  0.506849             77   \n",
       "2            0.994100           285                  0.335689            130   \n",
       "3            0.988828           112                  0.533333             62   \n",
       "4            0.991087           255                  0.425000            165   \n",
       "...               ...           ...                       ...            ...   \n",
       "1327         0.991407           200                  0.428266            113   \n",
       "1328         0.990272            94                  0.390041             67   \n",
       "1329         0.998153           170                  0.468320            107   \n",
       "1330         0.991837           144                  0.501742             83   \n",
       "1331         0.994444           284                  0.523985            155   \n",
       "\n",
       "      synonym_words/total_words  unstemmed  stemmed  score  \n",
       "0                      0.246479        424      412      4  \n",
       "1                      0.263699        356      345      4  \n",
       "2                      0.153121        750      750      4  \n",
       "3                      0.295238        217      209      3  \n",
       "4                      0.275000        702      677      4  \n",
       "...                         ...        ...      ...    ...  \n",
       "1327                   0.241970        529      519      4  \n",
       "1328                   0.278008        293      283      3  \n",
       "1329                   0.294766        427      415      3  \n",
       "1330                   0.289199        323      312      3  \n",
       "1331                   0.285978        596      575      4  \n",
       "\n",
       "[1332 rows x 19 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWRn_DMwtmLp"
   },
   "source": [
    "### &emsp; Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru213saPtmLp"
   },
   "source": [
    "Since we selected specific features when training the SVM model we need to do the same here, i.e. we need to extract the values from the same columns that were used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "20ser6YetmLq"
   },
   "outputs": [],
   "source": [
    "# specify the column headers of the features we want to keep\n",
    "selected_cols = ['unstemmed', 'stemmed', 'chars', 'POS', 'words', 'prompt_words', 'synonym_words', 'commas']\n",
    "# extract the values only from the selected columns\n",
    "selected_features = kaggle_data[selected_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwz0cCrNtmLq"
   },
   "source": [
    "Scale the data using the same scaler (MinMaxScaler()) that was used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UhVW4RJatmLr"
   },
   "outputs": [],
   "source": [
    "# scale the data with the same scaler used for the training and test set\n",
    "X_kaggle = scaler.transform(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDBjtbQMtmLs"
   },
   "source": [
    "### &emsp; Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrw_aStwtmLs"
   },
   "source": [
    "Make the predictions using the SVM model and display these predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Pll4kxhstmLs"
   },
   "outputs": [],
   "source": [
    "kaggle_predictions = opt_svm.predict(X_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zha2yOugtmLv",
    "outputId": "a059afe9-82b9-411f-b6a7-23192224a45f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, ..., 3, 3, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzkuswOptmLy"
   },
   "source": [
    "### &emsp;Output to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJcR0fZstmLz"
   },
   "source": [
    "To write the results to a csv file, we must first create a DataFrame with the appropriate format:\n",
    "- Columns (2 columns):\n",
    "    - *essayid*: the unique id for that essay\n",
    "    - *score*: the score for that essay\n",
    "- 200 lines:\n",
    "    - 1 header containing the column names\n",
    "    - 199 entries of essay-score pairs\n",
    "    \n",
    "To do this we can extract the essay ids from the *kaggle_data* DataFrame, and append a new column *score* filled with the model's predictions for each essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "IcGqG8pbtmL0",
    "outputId": "2a510d0e-f2e0-4852-b342-52cdb7412e0f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_predictions\",\n  \"rows\": 1332,\n  \"fields\": [\n    {\n      \"column\": \"essayid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 526,\n        \"min\": 0,\n        \"max\": 1799,\n        \"num_unique_values\": 1332,\n        \"samples\": [\n          163,\n          1194,\n          196\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_predictions"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-48cabea2-74a9-462e-9dd5-f3d37c880978\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essayid</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1457</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>503</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1151</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1345</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>344</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1077</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows  2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48cabea2-74a9-462e-9dd5-f3d37c880978')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-48cabea2-74a9-462e-9dd5-f3d37c880978 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-48cabea2-74a9-462e-9dd5-f3d37c880978');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-bf8857e8-2fc8-4cbf-b1b2-f668d7c6a630\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf8857e8-2fc8-4cbf-b1b2-f668d7c6a630')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-bf8857e8-2fc8-4cbf-b1b2-f668d7c6a630 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_d0fe0ac6-91b2-48ae-a65c-c1216e555858\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_predictions')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_d0fe0ac6-91b2-48ae-a65c-c1216e555858 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_predictions');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      essayid  score\n",
       "0        1457      4\n",
       "1         503      3\n",
       "2         253      4\n",
       "3         107      3\n",
       "4        1450      4\n",
       "...       ...    ...\n",
       "1327     1151      4\n",
       "1328     1015      3\n",
       "1329     1345      3\n",
       "1330      344      3\n",
       "1331     1077      4\n",
       "\n",
       "[1332 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the essayid column from kaggle_data\n",
    "df_predictions = kaggle_data[\"essayid\"]\n",
    "# convert the Series to a DataFrame\n",
    "df_predictions = df_predictions.to_frame()\n",
    "# create new column score and fill it with the model's predictions\n",
    "df_predictions[\"score\"] = pd.Series(kaggle_predictions)\n",
    "\n",
    "# display the DataFrame\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIWQjLkbtmL2"
   },
   "source": [
    "## &emsp;Using a Random Forest Classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5oKeawxtmL3"
   },
   "source": [
    "Unlike the SVM, the random forest classifier performs better when provided with all the features therefore we are not going to do feature selection here except for excluding the *essayid* column which simply provides the unique id of the essay and is not an indication of the essay's contents or quality thus it has no bearing on the score of the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rTQ-yqultmL4"
   },
   "outputs": [],
   "source": [
    "all_features = essay_data.iloc[:, 1:-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "425il_k-tmL5"
   },
   "source": [
    "### &emsp;Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjFg1AUtmL6"
   },
   "source": [
    "An interesting thing to note about the data is that there is a large imbalance between the frequency of the scores. The majority of essays are scored either a 3 or a 4. We can see this by using the *Counter* class from the *collections* library which counts the number of essays for each score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qb3ThwFktmL7",
    "outputId": "83329f97-430e-4f61-bdf3-8b5e78e137ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 583, 3: 557, 2: 110, 1: 18, 5: 60, 6: 4})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpt8wA6CtmL7"
   },
   "source": [
    "From this we can see that there are 583 essays that scored a 4 which makes up **43.8%** of the total essays whereas there are only 4 essays with a score of 6, this amounts to **0.45%** of total essays. This means that we are dealing with an imbalanced classification problem which is a classification problem in which the distribution of examples across the classes is skewed. This results in models having difficulty predicting these minority classes thus resulting in poorer performance overall.\n",
    "\n",
    "To combat this we can oversample these minority classes by using the Syntethic Minority Oversampling Technique which synthesizes new examples for these minority classes from existing ones. For this, we can use the *SMOTE* class from the *imblearn.over_sampling* module and resample the dataset from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_syOv1X5tmL8"
   },
   "outputs": [],
   "source": [
    "# k_neighbors is the number of nearest neighbours to construct syntethic samples\n",
    "# set random_state to an integer so that output is reproducible\n",
    "oversample = SMOTE(k_neighbors = 1, random_state = 209476)\n",
    "\n",
    "# resample the dataset\n",
    "features_over, label_over = oversample.fit_resample(all_features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNXf4rRltmL9"
   },
   "source": [
    "Split the oversampled dataset into the training and test set with the ratio 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "v0d4zRgltmL-"
   },
   "outputs": [],
   "source": [
    "# test_size parameter determines the proportion of the test set overt the entire dataset\n",
    "# an integer is passed in random_state to ensure reproducible output\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_over, label_over, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KptrXeovtmL_"
   },
   "source": [
    "Scale the feature values using the *StandardScaler()* function from the *sklearn.preprocessing* module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "6zs5qE-stmMA"
   },
   "outputs": [],
   "source": [
    "# define the scaler as the StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the training data which computes the mean and standard deviation of every feature in X_train\n",
    "# then we transform X_train to scale the data according to the computed mean and standard deviation\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Here we transform X_test using the mean and standard deviation of the corresponding features in X_train\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wikVI4XKtmMB"
   },
   "source": [
    "### &emsp; Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3OZTc0qtmMD"
   },
   "source": [
    "Create the random forest classifier and use GridSearchCV to search for the best parameters for this model based on the training set. Here the most important parameters are:\n",
    "- n_estimators: the number of trees to use\n",
    "- max_depth: the maximum depth of the tree\n",
    "\n",
    "The following block of code should only take ~5-15 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wRKKHm26tmMF",
    "outputId": "ce27957e-505f-4690-8e24-97f471003aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5; 1/16] START max_depth=2, n_estimators=5................................\n",
      "[CV 1/5; 1/16] END .max_depth=2, n_estimators=5;, score=0.613 total time=   0.0s\n",
      "[CV 2/5; 1/16] START max_depth=2, n_estimators=5................................\n",
      "[CV 2/5; 1/16] END .max_depth=2, n_estimators=5;, score=0.623 total time=   0.0s\n",
      "[CV 3/5; 1/16] START max_depth=2, n_estimators=5................................\n",
      "[CV 3/5; 1/16] END .max_depth=2, n_estimators=5;, score=0.632 total time=   0.0s\n",
      "[CV 4/5; 1/16] START max_depth=2, n_estimators=5................................\n",
      "[CV 4/5; 1/16] END .max_depth=2, n_estimators=5;, score=0.578 total time=   0.0s\n",
      "[CV 5/5; 1/16] START max_depth=2, n_estimators=5................................\n",
      "[CV 5/5; 1/16] END .max_depth=2, n_estimators=5;, score=0.623 total time=   0.0s\n",
      "[CV 1/5; 2/16] START max_depth=2, n_estimators=10...............................\n",
      "[CV 1/5; 2/16] END max_depth=2, n_estimators=10;, score=0.609 total time=   0.0s\n",
      "[CV 2/5; 2/16] START max_depth=2, n_estimators=10...............................\n",
      "[CV 2/5; 2/16] END max_depth=2, n_estimators=10;, score=0.623 total time=   0.0s\n",
      "[CV 3/5; 2/16] START max_depth=2, n_estimators=10...............................\n",
      "[CV 3/5; 2/16] END max_depth=2, n_estimators=10;, score=0.645 total time=   0.0s\n",
      "[CV 4/5; 2/16] START max_depth=2, n_estimators=10...............................\n",
      "[CV 4/5; 2/16] END max_depth=2, n_estimators=10;, score=0.585 total time=   0.0s\n",
      "[CV 5/5; 2/16] START max_depth=2, n_estimators=10...............................\n",
      "[CV 5/5; 2/16] END max_depth=2, n_estimators=10;, score=0.612 total time=   0.0s\n",
      "[CV 1/5; 3/16] START max_depth=2, n_estimators=15...............................\n",
      "[CV 1/5; 3/16] END max_depth=2, n_estimators=15;, score=0.623 total time=   0.1s\n",
      "[CV 2/5; 3/16] START max_depth=2, n_estimators=15...............................\n",
      "[CV 2/5; 3/16] END max_depth=2, n_estimators=15;, score=0.632 total time=   0.1s\n",
      "[CV 3/5; 3/16] START max_depth=2, n_estimators=15...............................\n",
      "[CV 3/5; 3/16] END max_depth=2, n_estimators=15;, score=0.637 total time=   0.1s\n",
      "[CV 4/5; 3/16] START max_depth=2, n_estimators=15...............................\n",
      "[CV 4/5; 3/16] END max_depth=2, n_estimators=15;, score=0.597 total time=   0.1s\n",
      "[CV 5/5; 3/16] START max_depth=2, n_estimators=15...............................\n",
      "[CV 5/5; 3/16] END max_depth=2, n_estimators=15;, score=0.644 total time=   0.1s\n",
      "[CV 1/5; 4/16] START max_depth=2, n_estimators=20...............................\n",
      "[CV 1/5; 4/16] END max_depth=2, n_estimators=20;, score=0.632 total time=   0.1s\n",
      "[CV 2/5; 4/16] START max_depth=2, n_estimators=20...............................\n",
      "[CV 2/5; 4/16] END max_depth=2, n_estimators=20;, score=0.648 total time=   0.1s\n",
      "[CV 3/5; 4/16] START max_depth=2, n_estimators=20...............................\n",
      "[CV 3/5; 4/16] END max_depth=2, n_estimators=20;, score=0.634 total time=   0.1s\n",
      "[CV 4/5; 4/16] START max_depth=2, n_estimators=20...............................\n",
      "[CV 4/5; 4/16] END max_depth=2, n_estimators=20;, score=0.594 total time=   0.1s\n",
      "[CV 5/5; 4/16] START max_depth=2, n_estimators=20...............................\n",
      "[CV 5/5; 4/16] END max_depth=2, n_estimators=20;, score=0.642 total time=   0.1s\n",
      "[CV 1/5; 5/16] START max_depth=5, n_estimators=5................................\n",
      "[CV 1/5; 5/16] END .max_depth=5, n_estimators=5;, score=0.755 total time=   0.0s\n",
      "[CV 2/5; 5/16] START max_depth=5, n_estimators=5................................\n",
      "[CV 2/5; 5/16] END .max_depth=5, n_estimators=5;, score=0.793 total time=   0.0s\n",
      "[CV 3/5; 5/16] START max_depth=5, n_estimators=5................................\n",
      "[CV 3/5; 5/16] END .max_depth=5, n_estimators=5;, score=0.771 total time=   0.0s\n",
      "[CV 4/5; 5/16] START max_depth=5, n_estimators=5................................\n",
      "[CV 4/5; 5/16] END .max_depth=5, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 5/5; 5/16] START max_depth=5, n_estimators=5................................\n",
      "[CV 5/5; 5/16] END .max_depth=5, n_estimators=5;, score=0.785 total time=   0.0s\n",
      "[CV 1/5; 6/16] START max_depth=5, n_estimators=10...............................\n",
      "[CV 1/5; 6/16] END max_depth=5, n_estimators=10;, score=0.770 total time=   0.1s\n",
      "[CV 2/5; 6/16] START max_depth=5, n_estimators=10...............................\n",
      "[CV 2/5; 6/16] END max_depth=5, n_estimators=10;, score=0.800 total time=   0.1s\n",
      "[CV 3/5; 6/16] START max_depth=5, n_estimators=10...............................\n",
      "[CV 3/5; 6/16] END max_depth=5, n_estimators=10;, score=0.780 total time=   0.1s\n",
      "[CV 4/5; 6/16] START max_depth=5, n_estimators=10...............................\n",
      "[CV 4/5; 6/16] END max_depth=5, n_estimators=10;, score=0.755 total time=   0.1s\n",
      "[CV 5/5; 6/16] START max_depth=5, n_estimators=10...............................\n",
      "[CV 5/5; 6/16] END max_depth=5, n_estimators=10;, score=0.778 total time=   0.1s\n",
      "[CV 1/5; 7/16] START max_depth=5, n_estimators=15...............................\n",
      "[CV 1/5; 7/16] END max_depth=5, n_estimators=15;, score=0.775 total time=   0.1s\n",
      "[CV 2/5; 7/16] START max_depth=5, n_estimators=15...............................\n",
      "[CV 2/5; 7/16] END max_depth=5, n_estimators=15;, score=0.793 total time=   0.1s\n",
      "[CV 3/5; 7/16] START max_depth=5, n_estimators=15...............................\n",
      "[CV 3/5; 7/16] END max_depth=5, n_estimators=15;, score=0.789 total time=   0.1s\n",
      "[CV 4/5; 7/16] START max_depth=5, n_estimators=15...............................\n",
      "[CV 4/5; 7/16] END max_depth=5, n_estimators=15;, score=0.766 total time=   0.1s\n",
      "[CV 5/5; 7/16] START max_depth=5, n_estimators=15...............................\n",
      "[CV 5/5; 7/16] END max_depth=5, n_estimators=15;, score=0.784 total time=   0.1s\n",
      "[CV 1/5; 8/16] START max_depth=5, n_estimators=20...............................\n",
      "[CV 1/5; 8/16] END max_depth=5, n_estimators=20;, score=0.775 total time=   0.1s\n",
      "[CV 2/5; 8/16] START max_depth=5, n_estimators=20...............................\n",
      "[CV 2/5; 8/16] END max_depth=5, n_estimators=20;, score=0.796 total time=   0.1s\n",
      "[CV 3/5; 8/16] START max_depth=5, n_estimators=20...............................\n",
      "[CV 3/5; 8/16] END max_depth=5, n_estimators=20;, score=0.789 total time=   0.1s\n",
      "[CV 4/5; 8/16] START max_depth=5, n_estimators=20...............................\n",
      "[CV 4/5; 8/16] END max_depth=5, n_estimators=20;, score=0.764 total time=   0.1s\n",
      "[CV 5/5; 8/16] START max_depth=5, n_estimators=20...............................\n",
      "[CV 5/5; 8/16] END max_depth=5, n_estimators=20;, score=0.789 total time=   0.1s\n",
      "[CV 1/5; 9/16] START max_depth=7, n_estimators=5................................\n",
      "[CV 1/5; 9/16] END .max_depth=7, n_estimators=5;, score=0.800 total time=   0.0s\n",
      "[CV 2/5; 9/16] START max_depth=7, n_estimators=5................................\n",
      "[CV 2/5; 9/16] END .max_depth=7, n_estimators=5;, score=0.809 total time=   0.0s\n",
      "[CV 3/5; 9/16] START max_depth=7, n_estimators=5................................\n",
      "[CV 3/5; 9/16] END .max_depth=7, n_estimators=5;, score=0.830 total time=   0.0s\n",
      "[CV 4/5; 9/16] START max_depth=7, n_estimators=5................................\n",
      "[CV 4/5; 9/16] END .max_depth=7, n_estimators=5;, score=0.805 total time=   0.0s\n",
      "[CV 5/5; 9/16] START max_depth=7, n_estimators=5................................\n",
      "[CV 5/5; 9/16] END .max_depth=7, n_estimators=5;, score=0.807 total time=   0.0s\n",
      "[CV 1/5; 10/16] START max_depth=7, n_estimators=10..............................\n",
      "[CV 1/5; 10/16] END max_depth=7, n_estimators=10;, score=0.820 total time=   0.1s\n",
      "[CV 2/5; 10/16] START max_depth=7, n_estimators=10..............................\n",
      "[CV 2/5; 10/16] END max_depth=7, n_estimators=10;, score=0.836 total time=   0.1s\n",
      "[CV 3/5; 10/16] START max_depth=7, n_estimators=10..............................\n",
      "[CV 3/5; 10/16] END max_depth=7, n_estimators=10;, score=0.832 total time=   0.1s\n",
      "[CV 4/5; 10/16] START max_depth=7, n_estimators=10..............................\n",
      "[CV 4/5; 10/16] END max_depth=7, n_estimators=10;, score=0.809 total time=   0.1s\n",
      "[CV 5/5; 10/16] START max_depth=7, n_estimators=10..............................\n",
      "[CV 5/5; 10/16] END max_depth=7, n_estimators=10;, score=0.792 total time=   0.1s\n",
      "[CV 1/5; 11/16] START max_depth=7, n_estimators=15..............................\n",
      "[CV 1/5; 11/16] END max_depth=7, n_estimators=15;, score=0.809 total time=   0.1s\n",
      "[CV 2/5; 11/16] START max_depth=7, n_estimators=15..............................\n",
      "[CV 2/5; 11/16] END max_depth=7, n_estimators=15;, score=0.850 total time=   0.1s\n",
      "[CV 3/5; 11/16] START max_depth=7, n_estimators=15..............................\n",
      "[CV 3/5; 11/16] END max_depth=7, n_estimators=15;, score=0.830 total time=   0.1s\n",
      "[CV 4/5; 11/16] START max_depth=7, n_estimators=15..............................\n",
      "[CV 4/5; 11/16] END max_depth=7, n_estimators=15;, score=0.819 total time=   0.1s\n",
      "[CV 5/5; 11/16] START max_depth=7, n_estimators=15..............................\n",
      "[CV 5/5; 11/16] END max_depth=7, n_estimators=15;, score=0.809 total time=   0.1s\n",
      "[CV 1/5; 12/16] START max_depth=7, n_estimators=20..............................\n",
      "[CV 1/5; 12/16] END max_depth=7, n_estimators=20;, score=0.816 total time=   0.1s\n",
      "[CV 2/5; 12/16] START max_depth=7, n_estimators=20..............................\n",
      "[CV 2/5; 12/16] END max_depth=7, n_estimators=20;, score=0.846 total time=   0.1s\n",
      "[CV 3/5; 12/16] START max_depth=7, n_estimators=20..............................\n",
      "[CV 3/5; 12/16] END max_depth=7, n_estimators=20;, score=0.821 total time=   0.1s\n",
      "[CV 4/5; 12/16] START max_depth=7, n_estimators=20..............................\n",
      "[CV 4/5; 12/16] END max_depth=7, n_estimators=20;, score=0.816 total time=   0.1s\n",
      "[CV 5/5; 12/16] START max_depth=7, n_estimators=20..............................\n",
      "[CV 5/5; 12/16] END max_depth=7, n_estimators=20;, score=0.801 total time=   0.1s\n",
      "[CV 1/5; 13/16] START max_depth=9, n_estimators=5...............................\n",
      "[CV 1/5; 13/16] END max_depth=9, n_estimators=5;, score=0.848 total time=   0.0s\n",
      "[CV 2/5; 13/16] START max_depth=9, n_estimators=5...............................\n",
      "[CV 2/5; 13/16] END max_depth=9, n_estimators=5;, score=0.830 total time=   0.0s\n",
      "[CV 3/5; 13/16] START max_depth=9, n_estimators=5...............................\n",
      "[CV 3/5; 13/16] END max_depth=9, n_estimators=5;, score=0.830 total time=   0.0s\n",
      "[CV 4/5; 13/16] START max_depth=9, n_estimators=5...............................\n",
      "[CV 4/5; 13/16] END max_depth=9, n_estimators=5;, score=0.826 total time=   0.0s\n",
      "[CV 5/5; 13/16] START max_depth=9, n_estimators=5...............................\n",
      "[CV 5/5; 13/16] END max_depth=9, n_estimators=5;, score=0.828 total time=   0.0s\n",
      "[CV 1/5; 14/16] START max_depth=9, n_estimators=10..............................\n",
      "[CV 1/5; 14/16] END max_depth=9, n_estimators=10;, score=0.850 total time=   0.1s\n",
      "[CV 2/5; 14/16] START max_depth=9, n_estimators=10..............................\n",
      "[CV 2/5; 14/16] END max_depth=9, n_estimators=10;, score=0.859 total time=   0.1s\n",
      "[CV 3/5; 14/16] START max_depth=9, n_estimators=10..............................\n",
      "[CV 3/5; 14/16] END max_depth=9, n_estimators=10;, score=0.846 total time=   0.1s\n",
      "[CV 4/5; 14/16] START max_depth=9, n_estimators=10..............................\n",
      "[CV 4/5; 14/16] END max_depth=9, n_estimators=10;, score=0.837 total time=   0.1s\n",
      "[CV 5/5; 14/16] START max_depth=9, n_estimators=10..............................\n",
      "[CV 5/5; 14/16] END max_depth=9, n_estimators=10;, score=0.855 total time=   0.1s\n",
      "[CV 1/5; 15/16] START max_depth=9, n_estimators=15..............................\n",
      "[CV 1/5; 15/16] END max_depth=9, n_estimators=15;, score=0.861 total time=   0.1s\n",
      "[CV 2/5; 15/16] START max_depth=9, n_estimators=15..............................\n",
      "[CV 2/5; 15/16] END max_depth=9, n_estimators=15;, score=0.875 total time=   0.1s\n",
      "[CV 3/5; 15/16] START max_depth=9, n_estimators=15..............................\n",
      "[CV 3/5; 15/16] END max_depth=9, n_estimators=15;, score=0.859 total time=   0.1s\n",
      "[CV 4/5; 15/16] START max_depth=9, n_estimators=15..............................\n",
      "[CV 4/5; 15/16] END max_depth=9, n_estimators=15;, score=0.843 total time=   0.1s\n",
      "[CV 5/5; 15/16] START max_depth=9, n_estimators=15..............................\n",
      "[CV 5/5; 15/16] END max_depth=9, n_estimators=15;, score=0.839 total time=   0.1s\n",
      "[CV 1/5; 16/16] START max_depth=9, n_estimators=20..............................\n",
      "[CV 1/5; 16/16] END max_depth=9, n_estimators=20;, score=0.857 total time=   0.2s\n",
      "[CV 2/5; 16/16] START max_depth=9, n_estimators=20..............................\n",
      "[CV 2/5; 16/16] END max_depth=9, n_estimators=20;, score=0.891 total time=   0.2s\n",
      "[CV 3/5; 16/16] START max_depth=9, n_estimators=20..............................\n",
      "[CV 3/5; 16/16] END max_depth=9, n_estimators=20;, score=0.861 total time=   0.2s\n",
      "[CV 4/5; 16/16] START max_depth=9, n_estimators=20..............................\n",
      "[CV 4/5; 16/16] END max_depth=9, n_estimators=20;, score=0.844 total time=   0.2s\n",
      "[CV 5/5; 16/16] START max_depth=9, n_estimators=20..............................\n",
      "[CV 5/5; 16/16] END max_depth=9, n_estimators=20;, score=0.850 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 5, 7, 9],\n",
       "                         &#x27;n_estimators&#x27;: [5, 10, 15, 20]},\n",
       "             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 5, 7, 9],\n",
       "                         &#x27;n_estimators&#x27;: [5, 10, 15, 20]},\n",
       "             verbose=10)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=9, n_estimators=20, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=9, n_estimators=20, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [2, 5, 7, 9],\n",
       "                         'n_estimators': [5, 10, 15, 20]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the RandomForestClassifier\n",
    "# provide an integer for random_state so that the output is reproducible\n",
    "rfc = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# provide list of possible parameter values\n",
    "parameters={'n_estimators' : [5, 10, 15, 20],\n",
    "            'max_depth' : [2, 5, 7, 9]}\n",
    "\n",
    "# in the first parameter the estimator for which we want to test out the parameter combinations is passed in\n",
    "# In the second parameter, try every combination of parameter values for the provided estimator (rfc)\n",
    "# verbose parameter controls its verbosity, a value of 1 just displays the total number of combinations\n",
    "opt_rfc = GridSearchCV(rfc, parameters, verbose=10)\n",
    "# fit the rfc to the training set and try all the parameter combinations to find the best one\n",
    "opt_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTkiiDLitmMF"
   },
   "source": [
    "After the model has been fitted to the training set and the best parameters have been chosen, we can see which of the parameter values had the best result by accessing the *best_params_* attribute of GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jMP-GQYtmMH",
    "outputId": "89c040cb-66c3-4c33-c57f-a7c6d2ce1fdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 20}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES_pIXSWtmMH"
   },
   "source": [
    "In order to evaluate the performance of the random forest classifier, we must first use it to predict the scores for the essays in the test set by calling the *.predict()* method of the model on *X_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xaIfeV3jtmMI"
   },
   "outputs": [],
   "source": [
    "opt_rfc_predictions = opt_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy4Jv-Y_tmMI"
   },
   "source": [
    "Now we can compute and display the confusion matrix to visualize the performance of the model. Note here that totaling the values along a row (which gives the total number of essays with that score) might give a different total than the first confusion matrix, this is the result of the oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "85MskemvtmMJ",
    "outputId": "2f6e4f0d-765e-481d-97bc-90c2f602e1ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x79d3db250cd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix using the actual scores of the essays in the test set and the model predictions\n",
    "cm = confusion_matrix(y_test, opt_rfc_predictions)\n",
    "# first parameter is the confusion matrix computed\n",
    "# display_labels parameter defines the list of possible labels (from 1 to 6), since essay scores range from 1-6\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[1,2,3,4,5,6])\n",
    "\n",
    "# display the confusion matrix\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5R61xm5gtmMK"
   },
   "source": [
    "We can see that the diagonal (upper-left to bottom-right) is lit up and other squares *not* on the diagonal are dark, this means that most of the model's predictions are correct and therefore the model seems to perform quite well. We can reinforce this notion by displaying the QWK score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhJMI20RtmMK",
    "outputId": "039d5156-9235-4199-d042-bba9ece3a140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747343352878785\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(y_test, opt_rfc_predictions, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aW3gEFetmMK"
   },
   "source": [
    "We can see that this score is a huge improvement over the score we obtained for our SVM (0.713) so we have successfully created a very accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F1C40F;color:black;font-size:22px;text-align:center;border-radius:10px 10px;font-weight:bold;border:2px solid #F1C40F;\">Thank You!!!!!!</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
